{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aAyAMkaIxd3I"
   },
   "source": [
    "# Importing the dataset into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-6crIx2oi4Pc"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn.metrics as metrics\n",
    "import sklearn.model_selection as ms\n",
    "import sklearn.preprocessing as preprocess\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hzWTMvpC9irH",
    "outputId": "09ab3691-0a19-4a0d-efe9-818cf6f13e1a"
   },
   "outputs": [],
   "source": [
    "# !pip install pyarabic\n",
    "# !pip install langdetect\n",
    "# !pip install nltk\n",
    "\n",
    "# from langdetect import detect\n",
    "# import pyarabic.araby as araby\n",
    "# nltk.download(\"all\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>{'متز': 1, 'نوع': 1, 'ما': 1, 'نظف': 1, 'وقع':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>{'احد': 1, 'سبب': 1, 'نجح': 1, 'امر': 2, 'كل':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>{'هدف': 1, 'نقل': 1, 'صخب': 1, 'شرع': 1, 'قهر'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>{'خلص': 3, 'بدء': 1, 'الل': 1, 'بهر': 1, 'زي':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>{'ياس': 1, 'جزء': 2, 'لا': 2, 'دبي': 1, 'ندق':...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               freq\n",
       "0      1  {'متز': 1, 'نوع': 1, 'ما': 1, 'نظف': 1, 'وقع':...\n",
       "1      1  {'احد': 1, 'سبب': 1, 'نجح': 1, 'امر': 2, 'كل':...\n",
       "2      1  {'هدف': 1, 'نقل': 1, 'صخب': 1, 'شرع': 1, 'قهر'...\n",
       "3      1  {'خلص': 3, 'بدء': 1, 'الل': 1, 'بهر': 1, 'زي':...\n",
       "4      1  {'ياس': 1, 'جزء': 2, 'لا': 2, 'دبي': 1, 'ندق':..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_folder_path=\"/home/youssef/AUC/Spring22/CSCE493002 - Machine Learning/project/datasets\"\n",
    "df = pd.read_csv(dataset_folder_path+'/freqEncoded.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop unecessary columns and neutral label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy=df[(df['label']!= 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/youssef/.local/lib/python3.8/site-packages/pandas/core/frame.py:3607: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._set_item(key, value)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>{'متز': 1, 'نوع': 1, 'ما': 1, 'نظف': 1, 'وقع':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>{'احد': 1, 'سبب': 1, 'نجح': 1, 'امر': 2, 'كل':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>{'هدف': 1, 'نقل': 1, 'صخب': 1, 'شرع': 1, 'قهر'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>{'خلص': 3, 'بدء': 1, 'الل': 1, 'بهر': 1, 'زي':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>{'ياس': 1, 'جزء': 2, 'لا': 2, 'دبي': 1, 'ندق':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66661</th>\n",
       "      <td>0</td>\n",
       "      <td>{'عرفش': 1, 'ليه': 1, 'كنت': 1, 'كمل': 1, 'وهي...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66662</th>\n",
       "      <td>0</td>\n",
       "      <td>{'لا': 3, 'سحق': 1, 'يكون': 1, 'كنق': 1, 'لنه'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66663</th>\n",
       "      <td>0</td>\n",
       "      <td>{'ضعف': 1, 'جدا': 1, 'ولم': 1, 'متع': 1, 'به':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66664</th>\n",
       "      <td>0</td>\n",
       "      <td>{'ملة': 1, 'جدا': 1, 'حمد': 1, 'حسن': 1, 'علو'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66665</th>\n",
       "      <td>0</td>\n",
       "      <td>{'لن': 1, 'رجع': 1, 'اله': 1, 'مرة': 1, 'خرى':...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66666 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                               freq\n",
       "0          1  {'متز': 1, 'نوع': 1, 'ما': 1, 'نظف': 1, 'وقع':...\n",
       "1          1  {'احد': 1, 'سبب': 1, 'نجح': 1, 'امر': 2, 'كل':...\n",
       "2          1  {'هدف': 1, 'نقل': 1, 'صخب': 1, 'شرع': 1, 'قهر'...\n",
       "3          1  {'خلص': 3, 'بدء': 1, 'الل': 1, 'بهر': 1, 'زي':...\n",
       "4          1  {'ياس': 1, 'جزء': 2, 'لا': 2, 'دبي': 1, 'ندق':...\n",
       "...      ...                                                ...\n",
       "66661      0  {'عرفش': 1, 'ليه': 1, 'كنت': 1, 'كمل': 1, 'وهي...\n",
       "66662      0  {'لا': 3, 'سحق': 1, 'يكون': 1, 'كنق': 1, 'لنه'...\n",
       "66663      0  {'ضعف': 1, 'جدا': 1, 'ولم': 1, 'متع': 1, 'به':...\n",
       "66664      0  {'ملة': 1, 'جدا': 1, 'حمد': 1, 'حسن': 1, 'علو'...\n",
       "66665      0  {'لن': 1, 'رجع': 1, 'اله': 1, 'مرة': 1, 'خرى':...\n",
       "\n",
       "[66666 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.reset_index(inplace=True,drop=True)\n",
    "df_copy[\"label\"]=df_copy[\"label\"].map({-1:0,1:1})\n",
    "# df_copy[df_copy[\"label\"]==-1].map() #=df_copy[\"label\"].str.replace(\"-1\",\"0\")\n",
    "df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy=pd.concat([df_copy.head(),df_copy.tail()]) #sampling 10 points for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unique Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_unique(df,colname):\n",
    "  sentences_arr=df[colname].to_numpy() #convert df to np array\n",
    "  words=' '.join(sentences_arr).split(' ') # join all strings into one string then splitting to get the words\n",
    "  words=np.array(words) #convert to np array\n",
    "  unique,counts = np.unique(words,return_counts=True)\n",
    "  return unique, counts\n",
    "\n",
    "def get_unique_dict(unique,counts):\n",
    "  unique_dict=dict(zip(unique,counts))\n",
    "  unique_dict=dict(sorted(unique_dict.items(), key=lambda item: item[1],reverse=True))\n",
    "  return unique_dict\n",
    "def remove_redundant_words(unique_dict):\n",
    "  stop_words=['من','على','عن','في','فى','و','ان','هذا','او','كتب','...','.','','الى','فيه','انه','قبل','//','..','،',':',\"؟\",'/']\n",
    "  for k, v in list(unique_dict.items()):\n",
    "      if(unique_dict[k]<100 or k in stop_words):\n",
    "        del unique_dict[k]\n",
    "\n",
    "  return unique_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_copy= pd.read_csv('freqEncoded.csv')\n",
    "#unique,counts=get_unique(df_copy,\"normalized\")\n",
    "unique,counts=get_unique(df_copy,\"freq\")\n",
    "unique_dict=get_unique_dict(unique,counts)\n",
    "unique_dict=remove_redundant_words(unique_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 Unique words:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'1,': 203}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"There are %d Unique words:\"%len(unique_dict))\n",
    "unique_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>{'متز': 1, 'نوع': 1, 'ما': 1, 'نظف': 1, 'وقع':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>{'احد': 1, 'سبب': 1, 'نجح': 1, 'امر': 2, 'كل':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>{'هدف': 1, 'نقل': 1, 'صخب': 1, 'شرع': 1, 'قهر'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>{'خلص': 3, 'بدء': 1, 'الل': 1, 'بهر': 1, 'زي':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>{'ياس': 1, 'جزء': 2, 'لا': 2, 'دبي': 1, 'ندق':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66661</th>\n",
       "      <td>0</td>\n",
       "      <td>{'عرفش': 1, 'ليه': 1, 'كنت': 1, 'كمل': 1, 'وهي...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66662</th>\n",
       "      <td>0</td>\n",
       "      <td>{'لا': 3, 'سحق': 1, 'يكون': 1, 'كنق': 1, 'لنه'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66663</th>\n",
       "      <td>0</td>\n",
       "      <td>{'ضعف': 1, 'جدا': 1, 'ولم': 1, 'متع': 1, 'به':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66664</th>\n",
       "      <td>0</td>\n",
       "      <td>{'ملة': 1, 'جدا': 1, 'حمد': 1, 'حسن': 1, 'علو'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66665</th>\n",
       "      <td>0</td>\n",
       "      <td>{'لن': 1, 'رجع': 1, 'اله': 1, 'مرة': 1, 'خرى':...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                               freq\n",
       "0          1  {'متز': 1, 'نوع': 1, 'ما': 1, 'نظف': 1, 'وقع':...\n",
       "1          1  {'احد': 1, 'سبب': 1, 'نجح': 1, 'امر': 2, 'كل':...\n",
       "2          1  {'هدف': 1, 'نقل': 1, 'صخب': 1, 'شرع': 1, 'قهر'...\n",
       "3          1  {'خلص': 3, 'بدء': 1, 'الل': 1, 'بهر': 1, 'زي':...\n",
       "4          1  {'ياس': 1, 'جزء': 2, 'لا': 2, 'دبي': 1, 'ندق':...\n",
       "66661      0  {'عرفش': 1, 'ليه': 1, 'كنت': 1, 'كمل': 1, 'وهي...\n",
       "66662      0  {'لا': 3, 'سحق': 1, 'يكون': 1, 'كنق': 1, 'لنه'...\n",
       "66663      0  {'ضعف': 1, 'جدا': 1, 'ولم': 1, 'متع': 1, 'به':...\n",
       "66664      0  {'ملة': 1, 'جدا': 1, 'حمد': 1, 'حسن': 1, 'علو'...\n",
       "66665      0  {'لن': 1, 'رجع': 1, 'اله': 1, 'مرة': 1, 'خرى':..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "#converting string dict to dict\n",
    "df_copy['freq']=df_copy['freq'].apply(lambda x: ast.literal_eval(x))\n",
    "print(type(df_copy.head()[\"freq\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>freq</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>{'متز': 1, 'نوع': 1, 'ما': 1, 'نظف': 1, 'وقع':...</td>\n",
       "      <td>متز نوع ما نظف وقع جهز شاطيء طعم</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>{'احد': 1, 'سبب': 1, 'نجح': 1, 'امر': 2, 'كل':...</td>\n",
       "      <td>احد سبب نجح امر كل شخص هذه دول عشق ترب نحن نحب...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>{'هدف': 1, 'نقل': 1, 'صخب': 1, 'شرع': 1, 'قهر'...</td>\n",
       "      <td>هدف نقل صخب شرع قهر هدء جبل شيش عرف حقق ما جرى...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>{'خلص': 3, 'بدء': 1, 'الل': 1, 'بهر': 1, 'زي':...</td>\n",
       "      <td>خلص بدء الل بهر زي فيل زرق حمد راد خطى رحل قرء...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>{'ياس': 1, 'جزء': 2, 'لا': 2, 'دبي': 1, 'ندق':...</td>\n",
       "      <td>ياس جزء لا دبي ندق كامل خدم ريح نفس وجد</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66661</th>\n",
       "      <td>0</td>\n",
       "      <td>{'عرفش': 1, 'ليه': 1, 'كنت': 1, 'كمل': 1, 'وهي...</td>\n",
       "      <td>عرفش ليه كنت كمل وهي مش عجب حدث بطء ممل روي اط...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66662</th>\n",
       "      <td>0</td>\n",
       "      <td>{'لا': 3, 'سحق': 1, 'يكون': 1, 'كنق': 1, 'لنه'...</td>\n",
       "      <td>لا سحق يكون كنق لنه سيء شي وجد خدم فطر صبح ستي...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66663</th>\n",
       "      <td>0</td>\n",
       "      <td>{'ضعف': 1, 'جدا': 1, 'ولم': 1, 'متع': 1, 'به':...</td>\n",
       "      <td>ضعف جدا ولم متع به كل قصه سرد لحل شهد بدن فكر</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66664</th>\n",
       "      <td>0</td>\n",
       "      <td>{'ملة': 1, 'جدا': 1, 'حمد': 1, 'حسن': 1, 'علو'...</td>\n",
       "      <td>ملة جدا حمد حسن علو فنن وصف عند دقق حد ثني قرء...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66665</th>\n",
       "      <td>0</td>\n",
       "      <td>{'لن': 1, 'رجع': 1, 'اله': 1, 'مرة': 1, 'خرى':...</td>\n",
       "      <td>لن رجع اله مرة خرى قرب بحر كان قدم ولا وجد خدم...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                               freq  \\\n",
       "0          1  {'متز': 1, 'نوع': 1, 'ما': 1, 'نظف': 1, 'وقع':...   \n",
       "1          1  {'احد': 1, 'سبب': 1, 'نجح': 1, 'امر': 2, 'كل':...   \n",
       "2          1  {'هدف': 1, 'نقل': 1, 'صخب': 1, 'شرع': 1, 'قهر'...   \n",
       "3          1  {'خلص': 3, 'بدء': 1, 'الل': 1, 'بهر': 1, 'زي':...   \n",
       "4          1  {'ياس': 1, 'جزء': 2, 'لا': 2, 'دبي': 1, 'ندق':...   \n",
       "66661      0  {'عرفش': 1, 'ليه': 1, 'كنت': 1, 'كمل': 1, 'وهي...   \n",
       "66662      0  {'لا': 3, 'سحق': 1, 'يكون': 1, 'كنق': 1, 'لنه'...   \n",
       "66663      0  {'ضعف': 1, 'جدا': 1, 'ولم': 1, 'متع': 1, 'به':...   \n",
       "66664      0  {'ملة': 1, 'جدا': 1, 'حمد': 1, 'حسن': 1, 'علو'...   \n",
       "66665      0  {'لن': 1, 'رجع': 1, 'اله': 1, 'مرة': 1, 'خرى':...   \n",
       "\n",
       "                                                    text  \n",
       "0                       متز نوع ما نظف وقع جهز شاطيء طعم  \n",
       "1      احد سبب نجح امر كل شخص هذه دول عشق ترب نحن نحب...  \n",
       "2      هدف نقل صخب شرع قهر هدء جبل شيش عرف حقق ما جرى...  \n",
       "3      خلص بدء الل بهر زي فيل زرق حمد راد خطى رحل قرء...  \n",
       "4                ياس جزء لا دبي ندق كامل خدم ريح نفس وجد  \n",
       "66661  عرفش ليه كنت كمل وهي مش عجب حدث بطء ممل روي اط...  \n",
       "66662  لا سحق يكون كنق لنه سيء شي وجد خدم فطر صبح ستي...  \n",
       "66663      ضعف جدا ولم متع به كل قصه سرد لحل شهد بدن فكر  \n",
       "66664  ملة جدا حمد حسن علو فنن وصف عند دقق حد ثني قرء...  \n",
       "66665  لن رجع اله مرة خرى قرب بحر كان قدم ولا وجد خدم...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#joined words into a sentence again to use sklearn model\n",
    "\n",
    "df_copy[\"text\"]=df_copy[\"freq\"].apply(lambda freq_dict: ' '.join(list(freq_dict.keys())) )\n",
    "df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  (7,) (7, 1) Test:  ((3,), (3, 1))\n"
     ]
    }
   ],
   "source": [
    "#Splitting data\n",
    "x=df_copy['text']\n",
    "y=np.expand_dims(df_copy['label'],axis=1)\n",
    "X_train,X_test,Y_train, Y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "print(\"Train: \" ,X_train.shape,Y_train.shape,\"Test: \",(X_test.shape,Y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer= TfidfVectorizer()\n",
    "tf_x_train = vectorizer.fit_transform(X_train)\n",
    "tf_x_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "row index (1000) out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(tf_x_train[\u001b[38;5;241m1000\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/sparse/_index.py:47\u001b[0m, in \u001b[0;36mIndexMixin.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m---> 47\u001b[0m     row, col \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;66;03m# Dispatch to specialized methods.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(row, INT_TYPES):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/sparse/_index.py:155\u001b[0m, in \u001b[0;36mIndexMixin._validate_indices\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    153\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(row)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m row \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39mM \u001b[38;5;129;01mor\u001b[39;00m row \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m M:\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrow index (\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m) out of range\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m row)\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m row \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    157\u001b[0m     row \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m M\n",
      "\u001b[0;31mIndexError\u001b[0m: row index (1000) out of range"
     ]
    }
   ],
   "source": [
    "print(tf_x_train[1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#SVM\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "#NN\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "import sklearn.model_selection as modsel\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = ['precision_macro', 'recall_macro','f1_macro','accuracy'] #used for CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_scores_to_df(scores):\n",
    "    df=pd.DataFrame(scores)\n",
    "    df.drop(columns=['fit_time','score_time'],inplace=True)\n",
    "    return df\n",
    "def display_heatmap(y_test,pred):\n",
    "    matrix=confusion_matrix(y_test,pred)\n",
    "    sns.heatmap(matrix,annot=True)\n",
    "def print_cv_scores(scores):\n",
    "    scores_df=convert_scores_to_df(scores)\n",
    "    print(scores_df)\n",
    "    print(\"Means:-\\n\",scores_df.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nerual Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdamOptimizer:\n",
    "    def __init__(self,beta1,beta2,alpha,eps=10e-8):\n",
    "#         self.params=params\n",
    "#         self.n_iter=n_iter\n",
    "        self.beta1=beta1\n",
    "        self.beta2=beta2\n",
    "        self.alpha=alpha\n",
    "        self.eps=eps\n",
    "        self.ms=[]\n",
    "        self.vs=[]\n",
    "        \n",
    "    def reset_params(self,layers):\n",
    "        self.ms=[ \n",
    "                  [np.zeros_like(layer.W), np.zeros_like(layer.b)] \n",
    "                  for layer in layers      \n",
    "                 ]\n",
    "        self.vs=self.ms.copy()\n",
    "        \n",
    "    def update(self,layers,N):\n",
    "        for i in range(len(layers)):\n",
    "            self.ms[i][0]= self.beta1*self.ms[i][0]*(1.0-self.beta1)*layers[i].dW\n",
    "            self.ms[i][1]= self.beta1*self.ms[i][1]*(1.0-self.beta1)*layers[i].db\n",
    "            \n",
    "            self.vs[i][0]= self.beta1*self.ms[i][0]*(1.0-self.beta2)*np.square(layers[i].dW)\n",
    "            self.vs[i][1]= self.beta1*self.ms[i][1]*(1.0-self.beta2)*np.square(layers[i].db)\n",
    "            \n",
    "            \n",
    "            deltaW = (-1 * self.alpha * self.ms[i][0]) / (np.sqrt(self.vs[i][0] + self.eps))\n",
    "            deltab = (-1 * self.alpha * self.ms[i][1]) / (np.sqrt(self.vs[i][1] + self.eps))\n",
    "\n",
    "            layers[i].W +=  deltaW/N\n",
    "            layers[i].b +=  deltab/N\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    \n",
    "    ### activations\n",
    "    def _relu(self,z):\n",
    "        return np.maximum(0,z)\n",
    "    def _diff_relu(self,z):\n",
    "        dZ=np.array(z,copy=True)\n",
    "        dZ[dZ<=0]=0\n",
    "        dZ[dZ>0]=1\n",
    "        return dZ\n",
    "    \n",
    "    def _identity(self,z):\n",
    "        return z\n",
    "    \n",
    "    def _identity_diff(self,z):\n",
    "        return np.ones_like(z)\n",
    "    \n",
    "    def _sigmoid(self,z):\n",
    "        return (1/(1+np.exp(-1*z)))\n",
    "\n",
    "    def _diff_sigmoid(self,z):\n",
    "        return self._sigmoid(z)*(1-self._sigmoid(z))\n",
    "    \n",
    "    def _softmax(self,z):\n",
    "        expZ= np.exp(z-np.max(z))\n",
    "        return expZ/expZ.sum(axis=0, keepdims=True)\n",
    "    def _diff_softmax(self,z):\n",
    "        pass\n",
    "\n",
    "    \n",
    "    ###########\n",
    "\n",
    "    def __init__(self,n_input,n_output, activation=\"identity\",name=None):\n",
    "        self.n_output= n_output\n",
    "        self.n_input= n_input\n",
    "        self.name= name\n",
    "        \n",
    "        if activation == \"identity\":\n",
    "            self.activation = self._identity\n",
    "            self.diff_act= self._identity_diff\n",
    "        \n",
    "        elif activation == \"sigmoid\":\n",
    "            self.activation = self._sigmoid\n",
    "            self.diff_act= self._diff_sigmoid\n",
    "            \n",
    "        elif activation == \"softmax\":\n",
    "            self.activation=self._softmax\n",
    "            self.diff_act=self._diff_softmax\n",
    "        elif activation ==\"relu\":\n",
    "            self.activation=self._relu\n",
    "            self.diff_act=self._diff_relu\n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "        self.W= np.random.randn(self.n_output,self.n_input)*np.sqrt(2/self.n_input)\n",
    "        self.b= np.random.randn(self.n_output,1)*np.sqrt(2/self.n_input)\n",
    "\n",
    "        self.dW= np.zeros_like(self.W)\n",
    "        self.db= np.zeros_like(self.b)\n",
    "        \n",
    "        self.Z= None\n",
    "        self.Ai = None\n",
    "    def print_shapes(self):\n",
    "        print(\"W: \",self.W.shape)\n",
    "        print(\"b: \",self.b.shape)\n",
    "#         print(\"W@Ai: \",self.W@Ai)\n",
    "    \n",
    "    def forward(self,Ai): #data dim \n",
    "#         print(\"FWD\")\n",
    "#         print(\"W:\",self.W.shape)\n",
    "#         print(\"Ai:\",Ai.shape)\n",
    "#         print(self.b.shape)\n",
    "        z =  np.add((self.W @ Ai),self.b)\n",
    "#         print(z.shape)\n",
    "        A = self.activation(z)\n",
    "#         print(\"A:\",A.shape)\n",
    "#         print(\"----------------\")\n",
    "\n",
    "        \n",
    "        self.Z = z\n",
    "        self.Ai = Ai\n",
    "        return A\n",
    "    \n",
    "    \n",
    "    def backward(self,inp):\n",
    "        \n",
    "#         print(\"input shape: \",end='')\n",
    "#         print(inp.shape)\n",
    "       \n",
    "        act_diff = self.diff_act(self.Z)\n",
    "#         print(\"act_diff shape: \",end='')\n",
    "#         print(act_diff.shape)\n",
    "        \n",
    "        tmp = inp * act_diff\n",
    "#         print(\"tmp shape: \",end='')\n",
    "#         print(tmp.shape)\n",
    "        \n",
    "        bet = tmp @ self.Ai.T # vector of 1s\n",
    "#         print(\"bet shape: \",end='')\n",
    "#         print(bet.shape)\n",
    "        \n",
    "        \n",
    "        e = np.ones((self.Ai.shape[1],1))\n",
    "        db = tmp @ e\n",
    "#         print(\"db shape: \",end='')\n",
    "#         print(db.shape)\n",
    "        self.dW = (self.dW + bet)\n",
    "        # print(\"dw:\",self.dW.shape,\"\\nlen:\",len(self.dW))\n",
    "        self.db = self.db + db\n",
    "        \n",
    "        \n",
    "        return self.W.T @ tmp\n",
    "    def print_weights(self):\n",
    "        print(\"\\n###################\")\n",
    "        if(self.name):\n",
    "            print(\"name: \",self.name)\n",
    "        print(\"dW: \",self.dW, \"W: \",self.W)\n",
    "    \n",
    "    def zeroing_delta(self):\n",
    "        self.dW= np.zeros_like(self.W)\n",
    "        self.db= np.zeros_like(self.b)\n",
    "#########################################################################################################\n",
    "class NN:\n",
    "    \n",
    "    ########\n",
    "    ## losses\n",
    "    def _MSE(self,y,yhat):\n",
    "        a=np.square(yhat-y)\n",
    "        a=np.sum(a)\n",
    "        b= 1/(2*y.shape[1])\n",
    "        return a*b\n",
    "\n",
    "    ## diff losses\n",
    "    def _diff_MSE(self,y,yhat):\n",
    "        return (yhat-y)\n",
    "    \n",
    "    def _binary_cross_entropy(self,y,yhat):\n",
    "        pass\n",
    "#         return -(y*np.log(yhat)+(1-y)*np.log(1-yhat)).mean()\n",
    "    def _diff_binary_cross_entropy(self,y,yhat):\n",
    "        loss=-((y*np.log(yhat)+(1-y)*np.log(1-yhat)).mean())\n",
    "        return loss\n",
    "    \n",
    "    #########\n",
    "    \n",
    "    def __init__(self,lr,optimizer,loss=\"binary_cross\"):\n",
    "        self.layers = []\n",
    "        self.alpha= lr\n",
    "        self.optimizer=optimizer\n",
    "        \n",
    "        if(loss==\"binary_cross\"):\n",
    "            self.loss=self._binary_cross_entropy\n",
    "            self.loss_diff=self._diff_binary_cross_entropy\n",
    "        elif loss==\"MSE\":\n",
    "            self.loss=self._MSE\n",
    "            self.loss_diff=self._diff_MSE\n",
    "        \n",
    "    \n",
    " \n",
    "    \n",
    "    def forward(self,x_train):\n",
    "        a=x_train\n",
    "#         print(a.shape)\n",
    "        for layer in self.layers:\n",
    "            a = layer.forward(a)\n",
    "#             print(a.shape)\n",
    "        \n",
    "        return a\n",
    "    \n",
    "    def backward(self,input):\n",
    "        gd = input\n",
    "        for layer in self.layers[::-1]:\n",
    "            gd = layer.backward(gd)\n",
    "            \n",
    "    def add_layer(self,n_input,n_output, activation=\"identity\",name=None):\n",
    "        self.layers.append(Layer(n_input,n_output, activation=activation,name=name))\n",
    "        \n",
    "    def fit(self, x_train,y_train, epochs=5): #data dim is MxN .. M no of examples.. N no of dimension\n",
    "        \n",
    "        M = x_train.shape[0]\n",
    "        \n",
    "        \n",
    "        x_train = x_train.T\n",
    "        y_train = y_train.T\n",
    "        \n",
    "        # print(x_train.shape,self.layers[0].W.shape)\n",
    "        # print(y_train.shape)\n",
    "        \n",
    "        for i in range(epochs):\n",
    "            self.optimizer.reset_params(self.layers)\n",
    "            print(\"Epoche {}/{}\".format(i+1,epochs))\n",
    "            y_hat= self.forward(x_train)\n",
    "            \n",
    "            dl_dyhat = self.loss_diff(y_train,y_hat)\n",
    "            print(\"loss=\",dl_dyhat)\n",
    "\n",
    "            \n",
    "            self.backward(dl_dyhat)\n",
    "            \n",
    "            # update using GD\n",
    "#             for i in range(len(self.layers)):\n",
    "#                 # layers[i].dW=layers[i].dW/N\n",
    "#                 # layers[i].db=layers[i].db/N\n",
    "#                 self.layers[i].W = self.layers[i].W - self.alpha * (self.layers[i].dW/M)\n",
    "#                 self.layers[i].b = self.layers[i].b - self.alpha * (self.layers[i].db/M)\n",
    "            self.optimizer.update(self.layers,M)\n",
    "            self.print_weights()\n",
    "            \n",
    "            # zeroing deltas\n",
    "            for layer in self.layers:\n",
    "                layer.zeroing_delta()\n",
    "            \n",
    "        print(\"Finished....\") \n",
    "            \n",
    "            \n",
    "        \n",
    "\n",
    "    \n",
    "    def predict(self,x_test): #data dim is NxD .. N no of examples.. D no of dimension\n",
    "#         print(x_test.shape)\n",
    "        y_hat= self.forward(x_test.T).T\n",
    "        print(y_hat)\n",
    "        y_hat[y_hat>0.5]=1\n",
    "        y_hat[y_hat<=0.5]=0\n",
    "#         print(y_hat.shape)\n",
    "        return y_hat\n",
    "                    \n",
    "    def print_weights(self):\n",
    "        for i in range(len(self.layers)):\n",
    "            print(\"layer i= \",i,end=\" \")\n",
    "            self.layers[i].print_weights()\n",
    "    def print_shapes(self):\n",
    "        for layer in self.layers:\n",
    "            layer.print_shapes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 158)\n",
      "(3, 158)\n",
      "(7, 1)\n",
      "(3, 1)\n"
     ]
    }
   ],
   "source": [
    "print(tf_x_train.shape)\n",
    "print(tf_x_test.shape)\n",
    "Y_train.reshape(Y_train.shape[0],1)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "adam= AdamOptimizer(beta1 = 0.8,beta2 = 0.999,alpha=0.001)\n",
    "nn = NN(lr=0.01,loss=\"binary_cross\",optimizer=adam)\n",
    "\n",
    "nn.add_layer(tf_x_train.shape[1],64,activation=\"relu\",name=\"l1\")\n",
    "nn.add_layer(64,32,activation = \"relu\",name=\"l2\")\n",
    "# nn.add_layer(32,16,activation = \"relu\",name=\"l3\")\n",
    "nn.add_layer(32,8,activation = \"relu\",name=\"l4\")\n",
    "nn.add_layer(8,1,activation = \"sigmoid\",name=\"l5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoche 1/3\n",
      "loss= 0.753395460258898\n",
      "layer i=  0 \n",
      "###################\n",
      "name:  l1\n",
      "dW:  [[ 0.00027632  0.00150063 -0.00087524 ...  0.          0.00195337\n",
      "   0.00027632]\n",
      " [ 0.          0.          0.         ...  0.00408493  0.\n",
      "   0.        ]\n",
      " [-0.00021957  0.          0.         ... -0.0018562   0.\n",
      "  -0.00021957]\n",
      " ...\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.00422284  0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [-0.00165186 -0.00446395 -0.00170849 ... -0.00177814  0.00400208\n",
      "  -0.00165186]] W:  [[ 0.12601403  0.01682171  0.05131037 ... -0.04852234  0.07369391\n",
      "   0.0613754 ]\n",
      " [-0.1861712  -0.00288368  0.01857762 ...  0.1263439   0.09526941\n",
      "  -0.14078629]\n",
      " [ 0.07646886  0.09656401 -0.06701928 ... -0.18403326 -0.32674651\n",
      "  -0.11107888]\n",
      " ...\n",
      " [-0.0250381   0.15350091 -0.10609755 ... -0.1474103  -0.13693038\n",
      "  -0.22397945]\n",
      " [ 0.00478108  0.19039952 -0.10564085 ... -0.09967595 -0.02694927\n",
      "  -0.00145093]\n",
      " [-0.04457926 -0.2205887   0.12436696 ...  0.04367144 -0.14882281\n",
      "   0.02977239]]\n",
      "layer i=  1 \n",
      "###################\n",
      "name:  l2\n",
      "dW:  [[-0.01001991 -0.00195125 -0.00040353 ...  0.         -0.00121367\n",
      "  -0.00915144]\n",
      " [ 0.01053579  0.00306918  0.00228841 ...  0.          0.00242178\n",
      "   0.0123198 ]\n",
      " [-0.00099909 -0.00018951 -0.00114637 ...  0.         -0.00083301\n",
      "  -0.00279233]\n",
      " ...\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.00206092  0.00158725  0.00100805 ...  0.          0.00072484\n",
      "   0.00336058]\n",
      " [ 0.00664158  0.          0.00238701 ...  0.          0.00371598\n",
      "   0.0106658 ]] W:  [[ 2.29645186e-01 -1.56676800e-01 -9.24275908e-02 ...  9.48169991e-02\n",
      "   9.92512701e-02  8.29874288e-02]\n",
      " [-7.07737661e-02 -3.61209138e-02  1.84339501e-01 ... -3.31865428e-01\n",
      "   9.93115169e-05  1.51328951e-01]\n",
      " [-5.17205038e-02  1.48636000e-01 -2.87580018e-01 ... -3.22924112e-02\n",
      "   2.12743618e-01 -3.55142483e-02]\n",
      " ...\n",
      " [-4.47927672e-01  2.24851229e-01  1.56919437e-02 ...  9.12424224e-02\n",
      "   1.71712612e-01 -1.06264049e-01]\n",
      " [ 4.03434345e-01  1.95720879e-01 -2.32849326e-01 ...  1.93366024e-01\n",
      "   3.05113363e-02 -1.11924108e-02]\n",
      " [ 9.09019102e-02 -3.56745796e-01  6.35730413e-02 ...  1.93341191e-01\n",
      "   1.14100397e-01  1.06761110e-01]]\n",
      "layer i=  2 \n",
      "###################\n",
      "name:  l4\n",
      "dW:  [[ 1.43804615e-02  5.89044894e-02  1.25293141e-02  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  1.06209384e-02  2.55824236e-02\n",
      "   7.79777652e-03  0.00000000e+00  0.00000000e+00  4.76575613e-02\n",
      "   4.53403195e-02  0.00000000e+00  1.42121180e-02  0.00000000e+00\n",
      "   8.72357964e-04  0.00000000e+00  0.00000000e+00  1.43076362e-03\n",
      "   1.44330726e-02  7.97949774e-03  7.29900118e-03  0.00000000e+00\n",
      "   9.97189779e-03  2.02132048e-02  2.98739346e-02  0.00000000e+00\n",
      "   4.68700888e-03  0.00000000e+00  4.77731035e-02  2.35392328e-03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-4.45194194e-03 -1.23605452e-02 -3.58191317e-03  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.03809888e-02\n",
      "  -8.84284901e-04  0.00000000e+00  0.00000000e+00 -1.15704290e-02\n",
      "  -1.03794021e-02  0.00000000e+00 -6.11334280e-03  0.00000000e+00\n",
      "  -1.91548715e-04  0.00000000e+00  0.00000000e+00 -8.20253341e-04\n",
      "  -3.26017048e-03 -2.73666284e-03 -2.45871566e-03  0.00000000e+00\n",
      "  -4.03212254e-03 -5.90609638e-03 -7.85242147e-03  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -1.45160113e-02 -3.51408649e-04]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 6.84901405e-02  2.80545709e-01  5.96736400e-02  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  5.05845773e-02  1.21841972e-01\n",
      "   3.71386419e-02  0.00000000e+00  0.00000000e+00  2.26979716e-01\n",
      "   2.15943338e-01  0.00000000e+00  6.76883673e-02  0.00000000e+00\n",
      "   4.15479848e-03  0.00000000e+00  0.00000000e+00  6.81432941e-03\n",
      "   6.87407128e-02  3.80041296e-02  3.47631136e-02  0.00000000e+00\n",
      "   4.74933771e-02  9.62698756e-02  1.42281246e-01  0.00000000e+00\n",
      "   2.23229204e-02  0.00000000e+00  2.27530012e-01  1.12110822e-02]\n",
      " [-7.26076039e-03 -2.97411446e-02 -6.32610764e-03  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -5.36256011e-03 -1.29166820e-02\n",
      "  -3.93713282e-03  0.00000000e+00  0.00000000e+00 -2.40625194e-02\n",
      "  -2.28925335e-02  0.00000000e+00 -7.17576300e-03  0.00000000e+00\n",
      "  -4.40457503e-04  0.00000000e+00  0.00000000e+00 -7.22399059e-04\n",
      "  -7.28732400e-03 -4.02888469e-03 -3.68529888e-03  0.00000000e+00\n",
      "  -5.03485653e-03 -1.02057390e-02 -1.50834854e-02  0.00000000e+00\n",
      "  -2.36649209e-03  0.00000000e+00 -2.41208572e-02 -1.18850657e-03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]] W:  [[-1.00532451e-01  2.74508787e-01 -3.83422509e-01  1.39346593e-01\n",
      "   3.79649777e-01 -2.67374136e-01  3.05256941e-01 -4.72816713e-02\n",
      "   4.45922121e-03 -1.43030586e-01  3.41962187e-01 -9.59997464e-02\n",
      "   1.96078381e-01 -5.05646395e-01  1.03599335e-01  1.25809109e-01\n",
      "   4.04347453e-01 -1.16044097e-01  1.73738433e-02 -1.56101202e-01\n",
      "   1.83193899e-01  1.96121546e-01  5.01023296e-01  3.19361011e-01\n",
      "  -1.83762710e-01  1.39750124e-01 -1.44459615e-01 -2.26208317e-01\n",
      "   6.00111198e-02 -6.66658702e-02 -1.45457521e-02  5.11703958e-02]\n",
      " [-3.68817786e-01  7.41645776e-02 -2.52448021e-01  4.92860484e-02\n",
      "   1.28368123e-01 -3.19268728e-01 -6.81015854e-03 -2.23515821e-01\n",
      "   3.30145824e-01 -4.62693360e-02 -3.76042690e-02 -1.98964959e-01\n",
      "  -3.66713838e-01 -1.51288795e-01  1.08753062e-01 -1.58138393e-01\n",
      "  -2.01323904e-01 -2.58641572e-01 -1.47849680e-01  1.35860077e-01\n",
      "  -3.52517149e-02 -2.64058159e-01 -2.47709096e-01  1.88933200e-01\n",
      "  -4.25509460e-01  5.19832411e-01  6.09972534e-02 -2.37454404e-01\n",
      "   3.04087279e-01 -5.68444608e-01 -9.97766417e-02  1.42145040e-01]\n",
      " [ 5.29789897e-01 -1.39415711e-01 -4.14304904e-01 -9.02427020e-02\n",
      "  -3.90953494e-01 -3.86244205e-01 -6.58161202e-01  3.38027038e-02\n",
      "  -4.32320818e-01  1.88336786e-01  9.15348355e-02 -3.55207468e-01\n",
      "  -3.00283967e-02 -4.71975135e-02  4.08926522e-01 -1.79413548e-01\n",
      "  -3.22711840e-01 -7.25149501e-02  1.37163408e-01 -1.27713285e-01\n",
      "  -2.63077075e-01  1.24267599e-01 -4.09141365e-01  2.61351946e-01\n",
      "   2.67167363e-01 -8.62791668e-03 -3.42038242e-01 -2.46825566e-01\n",
      "   3.40899307e-01 -1.65508920e-01  3.74062870e-01  3.81509962e-02]\n",
      " [-1.75240670e-01  4.49081084e-02  4.77309179e-01 -3.94503259e-01\n",
      "  -2.81206329e-01 -2.80453668e-01 -1.62942225e-02  1.59091232e-01\n",
      "   5.00998442e-02  1.04223434e-02 -4.90342185e-01 -3.12728713e-01\n",
      "  -4.17263010e-01 -2.57302721e-01  2.46635490e-01  1.29404752e-01\n",
      "  -2.05321965e-01 -1.78241168e-01  4.98642586e-02  2.34949859e-01\n",
      "  -3.18543445e-02  1.47311057e-01  9.99553502e-02  2.68952875e-01\n",
      "   1.98258786e-01 -5.74340944e-02  3.65819748e-01  3.26008089e-01\n",
      "  -1.70333802e-01 -4.10246325e-02 -3.87193239e-01  1.47491248e-01]\n",
      " [ 1.99052825e-01 -1.19662058e-02  1.04951064e-01 -7.28270524e-02\n",
      "  -1.32513269e-01 -3.56442910e-01  1.22629675e-01 -1.11458615e-01\n",
      "  -2.61535677e-01 -1.79000781e-01 -2.27511706e-01  7.87287578e-02\n",
      "  -2.93118143e-01 -1.44714951e-01 -1.20031612e-01 -4.27148242e-01\n",
      "  -1.46632664e-01 -2.51063397e-01 -2.48344548e-01  3.70901542e-01\n",
      "  -2.77727686e-01  2.27451110e-01  1.62982684e-01  1.66849791e-01\n",
      "  -1.41290923e-01  2.63303693e-01  5.26403650e-02 -1.24115232e-01\n",
      "   2.28694084e-01  1.00245069e-02 -4.55831230e-01 -2.98565505e-02]\n",
      " [-3.41302028e-02  3.03448065e-02  5.52114447e-02  3.39976324e-01\n",
      "   2.25769349e-02 -3.38369663e-01  1.73758920e-01  2.50639249e-01\n",
      "   3.09319981e-01 -1.11309650e-01  8.33451152e-02  2.85566638e-01\n",
      "  -1.43968257e-01  1.52404007e-01  2.96142494e-01 -5.86339033e-02\n",
      "  -4.76611751e-01 -1.10685130e-01 -1.43901937e-01  1.22287299e-01\n",
      "  -4.40699244e-02 -1.11334568e-01 -3.53744904e-03 -1.78124891e-01\n",
      "   1.65843031e-01 -1.33986329e-02  1.49489389e-01 -1.80599174e-01\n",
      "   2.32052495e-02  1.39782052e-01  3.93930931e-02  1.13674891e-01]\n",
      " [ 4.27357000e-02  3.65276464e-02  2.26475317e-01 -3.64965093e-01\n",
      "  -2.30120883e-02  3.52948688e-01  6.47571868e-02  1.26937346e-01\n",
      "  -5.09017257e-01 -1.79393234e-01  1.54222608e-01  7.77488708e-01\n",
      "  -2.98935582e-01 -5.90930247e-01 -3.64303465e-01  1.26413756e-01\n",
      "  -1.78218494e-01  3.20053149e-02 -4.91841046e-01  8.38444202e-02\n",
      "   3.10047673e-01  1.91238808e-01  4.37395965e-02  1.72477368e-01\n",
      "   9.68763117e-02 -3.13244485e-01  2.22607675e-01  5.84934757e-01\n",
      "   5.68327647e-04 -1.74926269e-01 -6.75276277e-02 -1.48544031e-01]\n",
      " [ 4.10894823e-01 -1.32121670e-01  2.82579847e-02 -1.23184669e-01\n",
      "   2.85687283e-01 -2.26296590e-01 -2.04256871e-01  3.49886870e-01\n",
      "  -3.03790335e-01  9.02744738e-03 -1.39801353e-01  3.25576855e-01\n",
      "   1.71054184e-01  1.90081952e-01 -1.41822521e-01 -3.54525240e-01\n",
      "   1.71592540e-01 -3.44458355e-01 -2.08552649e-01  1.81036943e-01\n",
      "   1.36899367e-01  5.18339854e-01 -2.22722466e-02 -3.49058451e-01\n",
      "   4.65775638e-01 -1.60608347e-01 -4.56712765e-01  2.20612296e-01\n",
      "   2.87279445e-01 -1.90568999e-01  7.40605338e-02 -5.02859442e-01]]\n",
      "layer i=  3 \n",
      "###################\n",
      "name:  l5\n",
      "dW:  [[0.42384245 0.         0.0472326  0.         0.         0.12820624\n",
      "  0.12828177 0.        ]] W:  [[ 1.51205316e-01  5.49884079e-01 -8.66856440e-02 -6.85917373e-01\n",
      "  -3.22914941e-04  7.20148890e-01 -7.63442518e-02 -6.35004406e-01]]\n",
      "Epoche 2/3\n",
      "loss= 0.753395460258898\n",
      "layer i=  0 \n",
      "###################\n",
      "name:  l1\n",
      "dW:  [[ 0.00027632  0.00150063 -0.00087524 ...  0.          0.00195337\n",
      "   0.00027632]\n",
      " [ 0.          0.          0.         ...  0.00408493  0.\n",
      "   0.        ]\n",
      " [-0.00021957  0.          0.         ... -0.0018562   0.\n",
      "  -0.00021957]\n",
      " ...\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.00422284  0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [-0.00165186 -0.00446395 -0.00170849 ... -0.00177814  0.00400208\n",
      "  -0.00165186]] W:  [[ 0.12601403  0.01682171  0.05131037 ... -0.04852234  0.07369391\n",
      "   0.0613754 ]\n",
      " [-0.1861712  -0.00288368  0.01857762 ...  0.1263439   0.09526941\n",
      "  -0.14078629]\n",
      " [ 0.07646886  0.09656401 -0.06701928 ... -0.18403326 -0.32674651\n",
      "  -0.11107888]\n",
      " ...\n",
      " [-0.0250381   0.15350091 -0.10609755 ... -0.1474103  -0.13693038\n",
      "  -0.22397945]\n",
      " [ 0.00478108  0.19039952 -0.10564085 ... -0.09967595 -0.02694927\n",
      "  -0.00145093]\n",
      " [-0.04457926 -0.2205887   0.12436696 ...  0.04367144 -0.14882281\n",
      "   0.02977239]]\n",
      "layer i=  1 \n",
      "###################\n",
      "name:  l2\n",
      "dW:  [[-0.01001991 -0.00195125 -0.00040353 ...  0.         -0.00121367\n",
      "  -0.00915144]\n",
      " [ 0.01053579  0.00306918  0.00228841 ...  0.          0.00242178\n",
      "   0.0123198 ]\n",
      " [-0.00099909 -0.00018951 -0.00114637 ...  0.         -0.00083301\n",
      "  -0.00279233]\n",
      " ...\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.00206092  0.00158725  0.00100805 ...  0.          0.00072484\n",
      "   0.00336058]\n",
      " [ 0.00664158  0.          0.00238701 ...  0.          0.00371598\n",
      "   0.0106658 ]] W:  [[ 2.29645186e-01 -1.56676800e-01 -9.24275908e-02 ...  9.48169991e-02\n",
      "   9.92512701e-02  8.29874288e-02]\n",
      " [-7.07737661e-02 -3.61209138e-02  1.84339501e-01 ... -3.31865428e-01\n",
      "   9.93115169e-05  1.51328951e-01]\n",
      " [-5.17205038e-02  1.48636000e-01 -2.87580018e-01 ... -3.22924112e-02\n",
      "   2.12743618e-01 -3.55142483e-02]\n",
      " ...\n",
      " [-4.47927672e-01  2.24851229e-01  1.56919437e-02 ...  9.12424224e-02\n",
      "   1.71712612e-01 -1.06264049e-01]\n",
      " [ 4.03434345e-01  1.95720879e-01 -2.32849326e-01 ...  1.93366024e-01\n",
      "   3.05113363e-02 -1.11924108e-02]\n",
      " [ 9.09019102e-02 -3.56745796e-01  6.35730413e-02 ...  1.93341191e-01\n",
      "   1.14100397e-01  1.06761110e-01]]\n",
      "layer i=  2 \n",
      "###################\n",
      "name:  l4\n",
      "dW:  [[ 1.43804615e-02  5.89044894e-02  1.25293141e-02  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  1.06209384e-02  2.55824236e-02\n",
      "   7.79777652e-03  0.00000000e+00  0.00000000e+00  4.76575613e-02\n",
      "   4.53403195e-02  0.00000000e+00  1.42121180e-02  0.00000000e+00\n",
      "   8.72357964e-04  0.00000000e+00  0.00000000e+00  1.43076362e-03\n",
      "   1.44330726e-02  7.97949774e-03  7.29900118e-03  0.00000000e+00\n",
      "   9.97189779e-03  2.02132048e-02  2.98739346e-02  0.00000000e+00\n",
      "   4.68700888e-03  0.00000000e+00  4.77731035e-02  2.35392328e-03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-4.45194194e-03 -1.23605452e-02 -3.58191317e-03  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.03809888e-02\n",
      "  -8.84284901e-04  0.00000000e+00  0.00000000e+00 -1.15704290e-02\n",
      "  -1.03794021e-02  0.00000000e+00 -6.11334280e-03  0.00000000e+00\n",
      "  -1.91548715e-04  0.00000000e+00  0.00000000e+00 -8.20253341e-04\n",
      "  -3.26017048e-03 -2.73666284e-03 -2.45871566e-03  0.00000000e+00\n",
      "  -4.03212254e-03 -5.90609638e-03 -7.85242147e-03  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -1.45160113e-02 -3.51408649e-04]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 6.84901405e-02  2.80545709e-01  5.96736400e-02  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  5.05845773e-02  1.21841972e-01\n",
      "   3.71386419e-02  0.00000000e+00  0.00000000e+00  2.26979716e-01\n",
      "   2.15943338e-01  0.00000000e+00  6.76883673e-02  0.00000000e+00\n",
      "   4.15479848e-03  0.00000000e+00  0.00000000e+00  6.81432941e-03\n",
      "   6.87407128e-02  3.80041296e-02  3.47631136e-02  0.00000000e+00\n",
      "   4.74933771e-02  9.62698756e-02  1.42281246e-01  0.00000000e+00\n",
      "   2.23229204e-02  0.00000000e+00  2.27530012e-01  1.12110822e-02]\n",
      " [-7.26076039e-03 -2.97411446e-02 -6.32610764e-03  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -5.36256011e-03 -1.29166820e-02\n",
      "  -3.93713282e-03  0.00000000e+00  0.00000000e+00 -2.40625194e-02\n",
      "  -2.28925335e-02  0.00000000e+00 -7.17576300e-03  0.00000000e+00\n",
      "  -4.40457503e-04  0.00000000e+00  0.00000000e+00 -7.22399059e-04\n",
      "  -7.28732400e-03 -4.02888469e-03 -3.68529888e-03  0.00000000e+00\n",
      "  -5.03485653e-03 -1.02057390e-02 -1.50834854e-02  0.00000000e+00\n",
      "  -2.36649209e-03  0.00000000e+00 -2.41208572e-02 -1.18850657e-03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]] W:  [[-1.00532451e-01  2.74508787e-01 -3.83422509e-01  1.39346593e-01\n",
      "   3.79649777e-01 -2.67374136e-01  3.05256941e-01 -4.72816713e-02\n",
      "   4.45922121e-03 -1.43030586e-01  3.41962187e-01 -9.59997464e-02\n",
      "   1.96078381e-01 -5.05646395e-01  1.03599335e-01  1.25809109e-01\n",
      "   4.04347453e-01 -1.16044097e-01  1.73738433e-02 -1.56101202e-01\n",
      "   1.83193899e-01  1.96121546e-01  5.01023296e-01  3.19361011e-01\n",
      "  -1.83762710e-01  1.39750124e-01 -1.44459615e-01 -2.26208317e-01\n",
      "   6.00111198e-02 -6.66658702e-02 -1.45457521e-02  5.11703958e-02]\n",
      " [-3.68817786e-01  7.41645776e-02 -2.52448021e-01  4.92860484e-02\n",
      "   1.28368123e-01 -3.19268728e-01 -6.81015854e-03 -2.23515821e-01\n",
      "   3.30145824e-01 -4.62693360e-02 -3.76042690e-02 -1.98964959e-01\n",
      "  -3.66713838e-01 -1.51288795e-01  1.08753062e-01 -1.58138393e-01\n",
      "  -2.01323904e-01 -2.58641572e-01 -1.47849680e-01  1.35860077e-01\n",
      "  -3.52517149e-02 -2.64058159e-01 -2.47709096e-01  1.88933200e-01\n",
      "  -4.25509460e-01  5.19832411e-01  6.09972534e-02 -2.37454404e-01\n",
      "   3.04087279e-01 -5.68444608e-01 -9.97766417e-02  1.42145040e-01]\n",
      " [ 5.29789897e-01 -1.39415711e-01 -4.14304904e-01 -9.02427020e-02\n",
      "  -3.90953494e-01 -3.86244205e-01 -6.58161202e-01  3.38027038e-02\n",
      "  -4.32320818e-01  1.88336786e-01  9.15348355e-02 -3.55207468e-01\n",
      "  -3.00283967e-02 -4.71975135e-02  4.08926522e-01 -1.79413548e-01\n",
      "  -3.22711840e-01 -7.25149501e-02  1.37163408e-01 -1.27713285e-01\n",
      "  -2.63077075e-01  1.24267599e-01 -4.09141365e-01  2.61351946e-01\n",
      "   2.67167363e-01 -8.62791668e-03 -3.42038242e-01 -2.46825566e-01\n",
      "   3.40899307e-01 -1.65508920e-01  3.74062870e-01  3.81509962e-02]\n",
      " [-1.75240670e-01  4.49081084e-02  4.77309179e-01 -3.94503259e-01\n",
      "  -2.81206329e-01 -2.80453668e-01 -1.62942225e-02  1.59091232e-01\n",
      "   5.00998442e-02  1.04223434e-02 -4.90342185e-01 -3.12728713e-01\n",
      "  -4.17263010e-01 -2.57302721e-01  2.46635490e-01  1.29404752e-01\n",
      "  -2.05321965e-01 -1.78241168e-01  4.98642586e-02  2.34949859e-01\n",
      "  -3.18543445e-02  1.47311057e-01  9.99553502e-02  2.68952875e-01\n",
      "   1.98258786e-01 -5.74340944e-02  3.65819748e-01  3.26008089e-01\n",
      "  -1.70333802e-01 -4.10246325e-02 -3.87193239e-01  1.47491248e-01]\n",
      " [ 1.99052825e-01 -1.19662058e-02  1.04951064e-01 -7.28270524e-02\n",
      "  -1.32513269e-01 -3.56442910e-01  1.22629675e-01 -1.11458615e-01\n",
      "  -2.61535677e-01 -1.79000781e-01 -2.27511706e-01  7.87287578e-02\n",
      "  -2.93118143e-01 -1.44714951e-01 -1.20031612e-01 -4.27148242e-01\n",
      "  -1.46632664e-01 -2.51063397e-01 -2.48344548e-01  3.70901542e-01\n",
      "  -2.77727686e-01  2.27451110e-01  1.62982684e-01  1.66849791e-01\n",
      "  -1.41290923e-01  2.63303693e-01  5.26403650e-02 -1.24115232e-01\n",
      "   2.28694084e-01  1.00245069e-02 -4.55831230e-01 -2.98565505e-02]\n",
      " [-3.41302028e-02  3.03448065e-02  5.52114447e-02  3.39976324e-01\n",
      "   2.25769349e-02 -3.38369663e-01  1.73758920e-01  2.50639249e-01\n",
      "   3.09319981e-01 -1.11309650e-01  8.33451152e-02  2.85566638e-01\n",
      "  -1.43968257e-01  1.52404007e-01  2.96142494e-01 -5.86339033e-02\n",
      "  -4.76611751e-01 -1.10685130e-01 -1.43901937e-01  1.22287299e-01\n",
      "  -4.40699244e-02 -1.11334568e-01 -3.53744904e-03 -1.78124891e-01\n",
      "   1.65843031e-01 -1.33986329e-02  1.49489389e-01 -1.80599174e-01\n",
      "   2.32052495e-02  1.39782052e-01  3.93930931e-02  1.13674891e-01]\n",
      " [ 4.27357000e-02  3.65276464e-02  2.26475317e-01 -3.64965093e-01\n",
      "  -2.30120883e-02  3.52948688e-01  6.47571868e-02  1.26937346e-01\n",
      "  -5.09017257e-01 -1.79393234e-01  1.54222608e-01  7.77488708e-01\n",
      "  -2.98935582e-01 -5.90930247e-01 -3.64303465e-01  1.26413756e-01\n",
      "  -1.78218494e-01  3.20053149e-02 -4.91841046e-01  8.38444202e-02\n",
      "   3.10047673e-01  1.91238808e-01  4.37395965e-02  1.72477368e-01\n",
      "   9.68763117e-02 -3.13244485e-01  2.22607675e-01  5.84934757e-01\n",
      "   5.68327647e-04 -1.74926269e-01 -6.75276277e-02 -1.48544031e-01]\n",
      " [ 4.10894823e-01 -1.32121670e-01  2.82579847e-02 -1.23184669e-01\n",
      "   2.85687283e-01 -2.26296590e-01 -2.04256871e-01  3.49886870e-01\n",
      "  -3.03790335e-01  9.02744738e-03 -1.39801353e-01  3.25576855e-01\n",
      "   1.71054184e-01  1.90081952e-01 -1.41822521e-01 -3.54525240e-01\n",
      "   1.71592540e-01 -3.44458355e-01 -2.08552649e-01  1.81036943e-01\n",
      "   1.36899367e-01  5.18339854e-01 -2.22722466e-02 -3.49058451e-01\n",
      "   4.65775638e-01 -1.60608347e-01 -4.56712765e-01  2.20612296e-01\n",
      "   2.87279445e-01 -1.90568999e-01  7.40605338e-02 -5.02859442e-01]]\n",
      "layer i=  3 \n",
      "###################\n",
      "name:  l5\n",
      "dW:  [[0.42384245 0.         0.0472326  0.         0.         0.12820624\n",
      "  0.12828177 0.        ]] W:  [[ 1.51205316e-01  5.49884079e-01 -8.66856440e-02 -6.85917373e-01\n",
      "  -3.22914941e-04  7.20148890e-01 -7.63442518e-02 -6.35004406e-01]]\n",
      "Epoche 3/3\n",
      "loss= 0.753395460258898\n",
      "layer i=  0 \n",
      "###################\n",
      "name:  l1\n",
      "dW:  [[ 0.00027632  0.00150063 -0.00087524 ...  0.          0.00195337\n",
      "   0.00027632]\n",
      " [ 0.          0.          0.         ...  0.00408493  0.\n",
      "   0.        ]\n",
      " [-0.00021957  0.          0.         ... -0.0018562   0.\n",
      "  -0.00021957]\n",
      " ...\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.00422284  0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [-0.00165186 -0.00446395 -0.00170849 ... -0.00177814  0.00400208\n",
      "  -0.00165186]] W:  [[ 0.12601403  0.01682171  0.05131037 ... -0.04852234  0.07369391\n",
      "   0.0613754 ]\n",
      " [-0.1861712  -0.00288368  0.01857762 ...  0.1263439   0.09526941\n",
      "  -0.14078629]\n",
      " [ 0.07646886  0.09656401 -0.06701928 ... -0.18403326 -0.32674651\n",
      "  -0.11107888]\n",
      " ...\n",
      " [-0.0250381   0.15350091 -0.10609755 ... -0.1474103  -0.13693038\n",
      "  -0.22397945]\n",
      " [ 0.00478108  0.19039952 -0.10564085 ... -0.09967595 -0.02694927\n",
      "  -0.00145093]\n",
      " [-0.04457926 -0.2205887   0.12436696 ...  0.04367144 -0.14882281\n",
      "   0.02977239]]\n",
      "layer i=  1 \n",
      "###################\n",
      "name:  l2\n",
      "dW:  [[-0.01001991 -0.00195125 -0.00040353 ...  0.         -0.00121367\n",
      "  -0.00915144]\n",
      " [ 0.01053579  0.00306918  0.00228841 ...  0.          0.00242178\n",
      "   0.0123198 ]\n",
      " [-0.00099909 -0.00018951 -0.00114637 ...  0.         -0.00083301\n",
      "  -0.00279233]\n",
      " ...\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.00206092  0.00158725  0.00100805 ...  0.          0.00072484\n",
      "   0.00336058]\n",
      " [ 0.00664158  0.          0.00238701 ...  0.          0.00371598\n",
      "   0.0106658 ]] W:  [[ 2.29645186e-01 -1.56676800e-01 -9.24275908e-02 ...  9.48169991e-02\n",
      "   9.92512701e-02  8.29874288e-02]\n",
      " [-7.07737661e-02 -3.61209138e-02  1.84339501e-01 ... -3.31865428e-01\n",
      "   9.93115169e-05  1.51328951e-01]\n",
      " [-5.17205038e-02  1.48636000e-01 -2.87580018e-01 ... -3.22924112e-02\n",
      "   2.12743618e-01 -3.55142483e-02]\n",
      " ...\n",
      " [-4.47927672e-01  2.24851229e-01  1.56919437e-02 ...  9.12424224e-02\n",
      "   1.71712612e-01 -1.06264049e-01]\n",
      " [ 4.03434345e-01  1.95720879e-01 -2.32849326e-01 ...  1.93366024e-01\n",
      "   3.05113363e-02 -1.11924108e-02]\n",
      " [ 9.09019102e-02 -3.56745796e-01  6.35730413e-02 ...  1.93341191e-01\n",
      "   1.14100397e-01  1.06761110e-01]]\n",
      "layer i=  2 \n",
      "###################\n",
      "name:  l4\n",
      "dW:  [[ 1.43804615e-02  5.89044894e-02  1.25293141e-02  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  1.06209384e-02  2.55824236e-02\n",
      "   7.79777652e-03  0.00000000e+00  0.00000000e+00  4.76575613e-02\n",
      "   4.53403195e-02  0.00000000e+00  1.42121180e-02  0.00000000e+00\n",
      "   8.72357964e-04  0.00000000e+00  0.00000000e+00  1.43076362e-03\n",
      "   1.44330726e-02  7.97949774e-03  7.29900118e-03  0.00000000e+00\n",
      "   9.97189779e-03  2.02132048e-02  2.98739346e-02  0.00000000e+00\n",
      "   4.68700888e-03  0.00000000e+00  4.77731035e-02  2.35392328e-03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-4.45194194e-03 -1.23605452e-02 -3.58191317e-03  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.03809888e-02\n",
      "  -8.84284901e-04  0.00000000e+00  0.00000000e+00 -1.15704290e-02\n",
      "  -1.03794021e-02  0.00000000e+00 -6.11334280e-03  0.00000000e+00\n",
      "  -1.91548715e-04  0.00000000e+00  0.00000000e+00 -8.20253341e-04\n",
      "  -3.26017048e-03 -2.73666284e-03 -2.45871566e-03  0.00000000e+00\n",
      "  -4.03212254e-03 -5.90609638e-03 -7.85242147e-03  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -1.45160113e-02 -3.51408649e-04]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 6.84901405e-02  2.80545709e-01  5.96736400e-02  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  5.05845773e-02  1.21841972e-01\n",
      "   3.71386419e-02  0.00000000e+00  0.00000000e+00  2.26979716e-01\n",
      "   2.15943338e-01  0.00000000e+00  6.76883673e-02  0.00000000e+00\n",
      "   4.15479848e-03  0.00000000e+00  0.00000000e+00  6.81432941e-03\n",
      "   6.87407128e-02  3.80041296e-02  3.47631136e-02  0.00000000e+00\n",
      "   4.74933771e-02  9.62698756e-02  1.42281246e-01  0.00000000e+00\n",
      "   2.23229204e-02  0.00000000e+00  2.27530012e-01  1.12110822e-02]\n",
      " [-7.26076039e-03 -2.97411446e-02 -6.32610764e-03  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -5.36256011e-03 -1.29166820e-02\n",
      "  -3.93713282e-03  0.00000000e+00  0.00000000e+00 -2.40625194e-02\n",
      "  -2.28925335e-02  0.00000000e+00 -7.17576300e-03  0.00000000e+00\n",
      "  -4.40457503e-04  0.00000000e+00  0.00000000e+00 -7.22399059e-04\n",
      "  -7.28732400e-03 -4.02888469e-03 -3.68529888e-03  0.00000000e+00\n",
      "  -5.03485653e-03 -1.02057390e-02 -1.50834854e-02  0.00000000e+00\n",
      "  -2.36649209e-03  0.00000000e+00 -2.41208572e-02 -1.18850657e-03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]] W:  [[-1.00532451e-01  2.74508787e-01 -3.83422509e-01  1.39346593e-01\n",
      "   3.79649777e-01 -2.67374136e-01  3.05256941e-01 -4.72816713e-02\n",
      "   4.45922121e-03 -1.43030586e-01  3.41962187e-01 -9.59997464e-02\n",
      "   1.96078381e-01 -5.05646395e-01  1.03599335e-01  1.25809109e-01\n",
      "   4.04347453e-01 -1.16044097e-01  1.73738433e-02 -1.56101202e-01\n",
      "   1.83193899e-01  1.96121546e-01  5.01023296e-01  3.19361011e-01\n",
      "  -1.83762710e-01  1.39750124e-01 -1.44459615e-01 -2.26208317e-01\n",
      "   6.00111198e-02 -6.66658702e-02 -1.45457521e-02  5.11703958e-02]\n",
      " [-3.68817786e-01  7.41645776e-02 -2.52448021e-01  4.92860484e-02\n",
      "   1.28368123e-01 -3.19268728e-01 -6.81015854e-03 -2.23515821e-01\n",
      "   3.30145824e-01 -4.62693360e-02 -3.76042690e-02 -1.98964959e-01\n",
      "  -3.66713838e-01 -1.51288795e-01  1.08753062e-01 -1.58138393e-01\n",
      "  -2.01323904e-01 -2.58641572e-01 -1.47849680e-01  1.35860077e-01\n",
      "  -3.52517149e-02 -2.64058159e-01 -2.47709096e-01  1.88933200e-01\n",
      "  -4.25509460e-01  5.19832411e-01  6.09972534e-02 -2.37454404e-01\n",
      "   3.04087279e-01 -5.68444608e-01 -9.97766417e-02  1.42145040e-01]\n",
      " [ 5.29789897e-01 -1.39415711e-01 -4.14304904e-01 -9.02427020e-02\n",
      "  -3.90953494e-01 -3.86244205e-01 -6.58161202e-01  3.38027038e-02\n",
      "  -4.32320818e-01  1.88336786e-01  9.15348355e-02 -3.55207468e-01\n",
      "  -3.00283967e-02 -4.71975135e-02  4.08926522e-01 -1.79413548e-01\n",
      "  -3.22711840e-01 -7.25149501e-02  1.37163408e-01 -1.27713285e-01\n",
      "  -2.63077075e-01  1.24267599e-01 -4.09141365e-01  2.61351946e-01\n",
      "   2.67167363e-01 -8.62791668e-03 -3.42038242e-01 -2.46825566e-01\n",
      "   3.40899307e-01 -1.65508920e-01  3.74062870e-01  3.81509962e-02]\n",
      " [-1.75240670e-01  4.49081084e-02  4.77309179e-01 -3.94503259e-01\n",
      "  -2.81206329e-01 -2.80453668e-01 -1.62942225e-02  1.59091232e-01\n",
      "   5.00998442e-02  1.04223434e-02 -4.90342185e-01 -3.12728713e-01\n",
      "  -4.17263010e-01 -2.57302721e-01  2.46635490e-01  1.29404752e-01\n",
      "  -2.05321965e-01 -1.78241168e-01  4.98642586e-02  2.34949859e-01\n",
      "  -3.18543445e-02  1.47311057e-01  9.99553502e-02  2.68952875e-01\n",
      "   1.98258786e-01 -5.74340944e-02  3.65819748e-01  3.26008089e-01\n",
      "  -1.70333802e-01 -4.10246325e-02 -3.87193239e-01  1.47491248e-01]\n",
      " [ 1.99052825e-01 -1.19662058e-02  1.04951064e-01 -7.28270524e-02\n",
      "  -1.32513269e-01 -3.56442910e-01  1.22629675e-01 -1.11458615e-01\n",
      "  -2.61535677e-01 -1.79000781e-01 -2.27511706e-01  7.87287578e-02\n",
      "  -2.93118143e-01 -1.44714951e-01 -1.20031612e-01 -4.27148242e-01\n",
      "  -1.46632664e-01 -2.51063397e-01 -2.48344548e-01  3.70901542e-01\n",
      "  -2.77727686e-01  2.27451110e-01  1.62982684e-01  1.66849791e-01\n",
      "  -1.41290923e-01  2.63303693e-01  5.26403650e-02 -1.24115232e-01\n",
      "   2.28694084e-01  1.00245069e-02 -4.55831230e-01 -2.98565505e-02]\n",
      " [-3.41302028e-02  3.03448065e-02  5.52114447e-02  3.39976324e-01\n",
      "   2.25769349e-02 -3.38369663e-01  1.73758920e-01  2.50639249e-01\n",
      "   3.09319981e-01 -1.11309650e-01  8.33451152e-02  2.85566638e-01\n",
      "  -1.43968257e-01  1.52404007e-01  2.96142494e-01 -5.86339033e-02\n",
      "  -4.76611751e-01 -1.10685130e-01 -1.43901937e-01  1.22287299e-01\n",
      "  -4.40699244e-02 -1.11334568e-01 -3.53744904e-03 -1.78124891e-01\n",
      "   1.65843031e-01 -1.33986329e-02  1.49489389e-01 -1.80599174e-01\n",
      "   2.32052495e-02  1.39782052e-01  3.93930931e-02  1.13674891e-01]\n",
      " [ 4.27357000e-02  3.65276464e-02  2.26475317e-01 -3.64965093e-01\n",
      "  -2.30120883e-02  3.52948688e-01  6.47571868e-02  1.26937346e-01\n",
      "  -5.09017257e-01 -1.79393234e-01  1.54222608e-01  7.77488708e-01\n",
      "  -2.98935582e-01 -5.90930247e-01 -3.64303465e-01  1.26413756e-01\n",
      "  -1.78218494e-01  3.20053149e-02 -4.91841046e-01  8.38444202e-02\n",
      "   3.10047673e-01  1.91238808e-01  4.37395965e-02  1.72477368e-01\n",
      "   9.68763117e-02 -3.13244485e-01  2.22607675e-01  5.84934757e-01\n",
      "   5.68327647e-04 -1.74926269e-01 -6.75276277e-02 -1.48544031e-01]\n",
      " [ 4.10894823e-01 -1.32121670e-01  2.82579847e-02 -1.23184669e-01\n",
      "   2.85687283e-01 -2.26296590e-01 -2.04256871e-01  3.49886870e-01\n",
      "  -3.03790335e-01  9.02744738e-03 -1.39801353e-01  3.25576855e-01\n",
      "   1.71054184e-01  1.90081952e-01 -1.41822521e-01 -3.54525240e-01\n",
      "   1.71592540e-01 -3.44458355e-01 -2.08552649e-01  1.81036943e-01\n",
      "   1.36899367e-01  5.18339854e-01 -2.22722466e-02 -3.49058451e-01\n",
      "   4.65775638e-01 -1.60608347e-01 -4.56712765e-01  2.20612296e-01\n",
      "   2.87279445e-01 -1.90568999e-01  7.40605338e-02 -5.02859442e-01]]\n",
      "layer i=  3 \n",
      "###################\n",
      "name:  l5\n",
      "dW:  [[0.42384245 0.         0.0472326  0.         0.         0.12820624\n",
      "  0.12828177 0.        ]] W:  [[ 1.51205316e-01  5.49884079e-01 -8.66856440e-02 -6.85917373e-01\n",
      "  -3.22914941e-04  7.20148890e-01 -7.63442518e-02 -6.35004406e-01]]\n",
      "Finished....\n"
     ]
    }
   ],
   "source": [
    "nn.fit(tf_x_train,Y_train,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.38567783]\n",
      " [0.3849155 ]\n",
      " [0.37586674]]\n"
     ]
    }
   ],
   "source": [
    "y_pred=nn.predict(tf_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['out.pckl']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "# dump=pickle.dumps(nn)\n",
    "dump(nn,\"out.pckl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.20683907]\n",
      " [0.22103681]\n",
      " [0.22143776]]\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "loadedCLF=load(\"out.pckl\")\n",
    "y_pred2=loadedCLF.predict(tf_x_test)\n",
    "y_pred2\n",
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(min(y_pred))\n",
    "max(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn.metrics as metrics\n",
    "import sklearn.model_selection as ms\n",
    "import sklearn.preprocessing as preprocess\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.51      0.67     20000\n",
      "\n",
      "    accuracy                           0.51     20000\n",
      "   macro avg       0.50      0.25      0.34     20000\n",
      "weighted avg       1.00      0.51      0.67     20000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/youssef/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/youssef/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/youssef/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Y_test\n",
    "print(classification_report(y_pred,Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "tf_list= pd.read_csv('/first.txt')\n",
    "array_tf_list = np.array(tf_list)\n",
    "test_list=pd.read_csv('/second.txt')\n",
    "array_test_list = np.array(test_list)\n",
    "tlabels= pd.read_csv('/third.txt')\n",
    "array_tlabels= np.array(tlabels)\n",
    "\n",
    "label_test=pd.read_csv('/fourth.txt')\n",
    "arr_lt= np.array(label_test)\n",
    "array_tf_list=np.reshape(array_tf_list,[256,5999])\n",
    "train_label_onehot =np.zeros((10,5999))\n",
    "for i in range(6000-1):\n",
    "  value=array_tlabels[i]\n",
    "  for row in range (1,10,1):\n",
    "    if (value==row):\n",
    "      train_label_onehot[value,i]=1\n",
    "\n",
    "def sigmoid(Z):\n",
    "    A = 1/(1+np.exp(-Z))\n",
    "    cache = Z\n",
    "    return A, cache\n",
    "\n",
    "def relu(Z):\n",
    "    A = np.maximum(0,Z)\n",
    "    cache = Z\n",
    "    return A, cache\n",
    "\n",
    "def softmax(Z):\n",
    "    e_x = np.exp(Z)\n",
    "    A= e_x / np.sum(np.exp(Z))\n",
    "    cache=Z\n",
    "    return A,cache\n",
    "\n",
    "def relu_backward(dA, cache):\n",
    "    Z = cache\n",
    "    dZ = np.array(dA, copy=True)\n",
    "    dZ[Z <= 0] = 0\n",
    "    assert (dZ.shape == Z.shape)\n",
    "    return dZ\n",
    "\n",
    "def sigmoid_backward(dA, cache):\n",
    "    Z = cache\n",
    "    s = 1/(1+np.exp(-Z))\n",
    "    dZ = dA * s * (1-s)\n",
    "    assert (dZ.shape == Z.shape)\n",
    "    return dZ\n",
    "\n",
    "def softmax_backward(Z,cache):\n",
    "    Z=cache\n",
    "    length=10\n",
    "    dZ=np.zeros((6000-1,10))\n",
    "    Z=np.transpose(Z)\n",
    "    for row in range (0,5999):\n",
    "            den=(np.sum(np.exp(Z[row,:])))*(np.sum(np.exp(Z[row,:])))\n",
    "            for col in range (0,10):\n",
    "                sums=0\n",
    "                for j in range (0,10):\n",
    "                    if (j!=col):\n",
    "                        sums=sums+(math.exp(Z[row,j]))\n",
    "\n",
    "                dZ[row,col]=(math.exp(Z[row,col])*sums)/den\n",
    "    dZ=np.transpose(dZ)\n",
    "    Z=np.transpose(Z)\n",
    "    assert (dZ.shape == Z.shape)\n",
    "    return dZ\n",
    "\n",
    "def initialize_parameters_deep(mylay_dimensions):\n",
    "    parameters = {}\n",
    "    L = len(mylay_dimensions)\n",
    "    for l in range(1, L):\n",
    "        parameters['W' + str(l)] = np.random.randn(mylay_dimensions[l], mylay_dimensions[l-1]) / np.sqrt(mylay_dimensions[l-1]) #*0.01\n",
    "        parameters['b' + str(l)] = np.zeros((mylay_dimensions[l], 1))\n",
    "    return parameters\n",
    "\n",
    "def for_front(A, W, b):\n",
    "    Z = np.dot(W,A) +b\n",
    "    cache = (A, W, b)\n",
    "    assert(Z.shape == (W.shape[0], A.shape[1]))\n",
    "    return Z, cache\n",
    "\n",
    "def for_active(A_prev, W, b, activation):\n",
    "    if activation == \"sigmoid\":\n",
    "        Z, linear_cache = for_front(A_prev, W, b)\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "    elif activation == \"relu\":\n",
    "        Z, linear_cache = for_front(A_prev, W, b)\n",
    "        A, activation_cache = relu(Z)\n",
    "    elif activation == \"softmax\":\n",
    "        Z, linear_cache = for_front(A_prev, W, b)\n",
    "        A, activation_cache = softmax(Z)\n",
    "    cache = (linear_cache, activation_cache)\n",
    "    return A, cache\n",
    "\n",
    "def my_mod_for(X, parameters):\n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters)\n",
    "    for l in range(1, L):\n",
    "        A_prev = A\n",
    "        A, cache = for_active(A_prev, parameters['W' + str(l)], parameters['b' + str(l)], activation = \"relu\")\n",
    "        caches.append(cache)\n",
    "    AL, cache = for_active(A, parameters['W' + str(L)], parameters['b' + str(L)], activation = \"softmax\")\n",
    "    caches.append(cache)\n",
    "    return AL, caches\n",
    "\n",
    "def calc_cost(AL, Y):\n",
    "    m = Y.shape[1]\n",
    "    cost = (-1 / m) * np.sum(np.multiply(Y, np.log(AL)) + np.multiply(1 - Y, np.log(1 - AL)))\n",
    "    return cost\n",
    "\n",
    "def linear_backward(dZ, cache):\n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "    dW = 1./m * np.dot(dZ,A_prev.T)\n",
    "    db = (1/m)*np.sum(dZ, axis=1, keepdims=True);\n",
    "    dA_prev = np.dot(W.T,dZ)\n",
    "    return dA_prev, dW, db\n",
    "\n",
    "def lin_back(dA, cache, activation):\n",
    "    linear_cache, activation_cache = cache\n",
    "    if activation == \"relu\":\n",
    "        dZ = relu_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "    elif activation == \"sigmoid\":\n",
    "        dZ = sigmoid_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "    elif activation == \"softmax\":\n",
    "        dZ = softmax_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "    return dA_prev, dW, db\n",
    "\n",
    "def my_mod_back(AL, Y, caches):\n",
    "    arbit_arr = {}\n",
    "    L = len(caches)\n",
    "    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
    "    M=len(my_network_dimensions)\n",
    "    current_cache = caches[M-2]\n",
    "    arbit_arr[\"dA\"+str(M-1)], arbit_arr[\"dW\"+str(M-1)], arbit_arr[\"db\"+str(M-1)] = lin_back(dAL, current_cache, activation = \"softmax\")#M-1\n",
    "    for l in reversed(range(L-1)):\n",
    "        current_cache = caches[l]\n",
    "        dA_prev_temp, dW_temp, db_temp = lin_back(arbit_arr[\"dA\" + str(l + 2)], current_cache, activation = \"relu\")\n",
    "        arbit_arr[\"dA\" + str(l + 1)] = dA_prev_temp\n",
    "        arbit_arr[\"dW\" + str(l + 1)] = dW_temp\n",
    "        arbit_arr[\"db\" + str(l + 1)] = db_temp\n",
    "    return arbit_arr\n",
    "\n",
    "def change_weights(parameters, arbit_arr, learning_rate):\n",
    "    for l in range(len_update-1):\n",
    "        parameters[\"W\" + str(l+1)] =parameters[\"W\" + str(l+1)] - (learning_rate*arbit_arr[\"dW\" + str(l+1)])\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - (learning_rate*arbit_arr[\"db\" + str(l+1)])\n",
    "    return parameters\n",
    "\n",
    "def plot_graph(cost_plot):\n",
    "    x_value=list(range(1,len(cost_plot)+1))\n",
    "    plt.xlabel('iteration')\n",
    "    plt.ylabel('cost')\n",
    "    plt.plot(x_value,cost_plot,0.,color='g')\n",
    "my_network_dimensions = [256,150,100,50,10]\n",
    "len_update=len(my_network_dimensions)\n",
    "def my_lay_mod(X, Y, my_network_dimensions, learning_rate , num_iterations , print_cost=False):#lr was 0.009\n",
    "    costs = []\n",
    "    cost_plot=np.zeros(num_iterations)\n",
    "    parameters = initialize_parameters_deep(my_network_dimensions)\n",
    "    for i in range(0, num_iterations):\n",
    "        AL, caches = my_mod_for(X, parameters)\n",
    "        cost =calc_cost(AL, Y)\n",
    "        arbit_arr = my_mod_back(AL, Y, caches)\n",
    "        parameters = change_weights(parameters, arbit_arr, learning_rate)\n",
    "        cost_plot[i]=cost;\n",
    "    plot_graph(cost_plot)\n",
    "    return parameters\n",
    "parameters = my_lay_mod(array_tf_list, train_label_onehot, my_network_dimensions,learning_rate = 0.005, num_iterations =50 , print_cost = True)\n",
    "for weight in parameters:\n",
    "    print(weight)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "detect_language.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
