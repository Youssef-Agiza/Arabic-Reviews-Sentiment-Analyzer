{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aAyAMkaIxd3I"
   },
   "source": [
    "# Importing the dataset into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-6crIx2oi4Pc"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn.metrics as metrics\n",
    "import sklearn.model_selection as ms\n",
    "import sklearn.preprocessing as preprocess\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batching\n",
    "#mini batch gradients\n",
    "#shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hzWTMvpC9irH",
    "outputId": "09ab3691-0a19-4a0d-efe9-818cf6f13e1a"
   },
   "outputs": [],
   "source": [
    "# !pip install pyarabic\n",
    "# !pip install langdetect\n",
    "# !pip install nltk\n",
    "\n",
    "# from langdetect import detect\n",
    "# import pyarabic.araby as araby\n",
    "# nltk.download(\"all\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>{'متز': 1, 'نوع': 1, 'ما': 1, 'نظف': 1, 'وقع':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>{'احد': 1, 'سبب': 1, 'نجح': 1, 'امر': 2, 'كل':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>{'هدف': 1, 'نقل': 1, 'صخب': 1, 'شرع': 1, 'قهر'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>{'خلص': 3, 'بدء': 1, 'الل': 1, 'بهر': 1, 'زي':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>{'ياس': 1, 'جزء': 2, 'لا': 2, 'دبي': 1, 'ندق':...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               freq\n",
       "0      1  {'متز': 1, 'نوع': 1, 'ما': 1, 'نظف': 1, 'وقع':...\n",
       "1      1  {'احد': 1, 'سبب': 1, 'نجح': 1, 'امر': 2, 'كل':...\n",
       "2      1  {'هدف': 1, 'نقل': 1, 'صخب': 1, 'شرع': 1, 'قهر'...\n",
       "3      1  {'خلص': 3, 'بدء': 1, 'الل': 1, 'بهر': 1, 'زي':...\n",
       "4      1  {'ياس': 1, 'جزء': 2, 'لا': 2, 'دبي': 1, 'ندق':..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_folder_path=\"/home/youssef/AUC/Spring22/CSCE493002 - Machine Learning/project/datasets\"\n",
    "df = pd.read_csv(dataset_folder_path+'/freqEncoded.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop unecessary columns and neutral label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy=df[(df['label']!= 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/youssef/.local/lib/python3.8/site-packages/pandas/core/frame.py:3607: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._set_item(key, value)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>{'متز': 1, 'نوع': 1, 'ما': 1, 'نظف': 1, 'وقع':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>{'احد': 1, 'سبب': 1, 'نجح': 1, 'امر': 2, 'كل':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>{'هدف': 1, 'نقل': 1, 'صخب': 1, 'شرع': 1, 'قهر'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>{'خلص': 3, 'بدء': 1, 'الل': 1, 'بهر': 1, 'زي':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>{'ياس': 1, 'جزء': 2, 'لا': 2, 'دبي': 1, 'ندق':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66661</th>\n",
       "      <td>0</td>\n",
       "      <td>{'عرفش': 1, 'ليه': 1, 'كنت': 1, 'كمل': 1, 'وهي...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66662</th>\n",
       "      <td>0</td>\n",
       "      <td>{'لا': 3, 'سحق': 1, 'يكون': 1, 'كنق': 1, 'لنه'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66663</th>\n",
       "      <td>0</td>\n",
       "      <td>{'ضعف': 1, 'جدا': 1, 'ولم': 1, 'متع': 1, 'به':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66664</th>\n",
       "      <td>0</td>\n",
       "      <td>{'ملة': 1, 'جدا': 1, 'حمد': 1, 'حسن': 1, 'علو'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66665</th>\n",
       "      <td>0</td>\n",
       "      <td>{'لن': 1, 'رجع': 1, 'اله': 1, 'مرة': 1, 'خرى':...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66666 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                               freq\n",
       "0          1  {'متز': 1, 'نوع': 1, 'ما': 1, 'نظف': 1, 'وقع':...\n",
       "1          1  {'احد': 1, 'سبب': 1, 'نجح': 1, 'امر': 2, 'كل':...\n",
       "2          1  {'هدف': 1, 'نقل': 1, 'صخب': 1, 'شرع': 1, 'قهر'...\n",
       "3          1  {'خلص': 3, 'بدء': 1, 'الل': 1, 'بهر': 1, 'زي':...\n",
       "4          1  {'ياس': 1, 'جزء': 2, 'لا': 2, 'دبي': 1, 'ندق':...\n",
       "...      ...                                                ...\n",
       "66661      0  {'عرفش': 1, 'ليه': 1, 'كنت': 1, 'كمل': 1, 'وهي...\n",
       "66662      0  {'لا': 3, 'سحق': 1, 'يكون': 1, 'كنق': 1, 'لنه'...\n",
       "66663      0  {'ضعف': 1, 'جدا': 1, 'ولم': 1, 'متع': 1, 'به':...\n",
       "66664      0  {'ملة': 1, 'جدا': 1, 'حمد': 1, 'حسن': 1, 'علو'...\n",
       "66665      0  {'لن': 1, 'رجع': 1, 'اله': 1, 'مرة': 1, 'خرى':...\n",
       "\n",
       "[66666 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.reset_index(inplace=True,drop=True)\n",
    "df_copy[\"label\"]=df_copy[\"label\"].map({-1:0,1:1})\n",
    "# df_copy[df_copy[\"label\"]==-1].map() #=df_copy[\"label\"].str.replace(\"-1\",\"0\")\n",
    "df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_copy=pd.concat([df_copy.head(),df_copy.tail()]) #sampling 10 points for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unique Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_unique(df,colname):\n",
    "  sentences_arr=df[colname].to_numpy() #convert df to np array\n",
    "  words=' '.join(sentences_arr).split(' ') # join all strings into one string then splitting to get the words\n",
    "  words=np.array(words) #convert to np array\n",
    "  unique,counts = np.unique(words,return_counts=True)\n",
    "  return unique, counts\n",
    "\n",
    "def get_unique_dict(unique,counts):\n",
    "  unique_dict=dict(zip(unique,counts))\n",
    "  unique_dict=dict(sorted(unique_dict.items(), key=lambda item: item[1],reverse=True))\n",
    "  return unique_dict\n",
    "def remove_redundant_words(unique_dict):\n",
    "  stop_words=['من','على','عن','في','فى','و','ان','هذا','او','كتب','...','.','','الى','فيه','انه','قبل','//','..','،',':',\"؟\",'/']\n",
    "  for k, v in list(unique_dict.items()):\n",
    "      if(unique_dict[k]<100 or k in stop_words):\n",
    "        del unique_dict[k]\n",
    "\n",
    "  return unique_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_copy= pd.read_csv('freqEncoded.csv')\n",
    "#unique,counts=get_unique(df_copy,\"normalized\")\n",
    "unique,counts=get_unique(df_copy,\"freq\")\n",
    "unique_dict=get_unique_dict(unique,counts)\n",
    "unique_dict=remove_redundant_words(unique_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2838 Unique words:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'1,': 1724707,\n",
       " '2,': 254179,\n",
       " '3,': 66119,\n",
       " '1}': 65678,\n",
       " '4,': 24199,\n",
       " \"'جدا':\": 16799,\n",
       " \"'لا':\": 16265,\n",
       " \"'ما':\": 13117,\n",
       " \"'كان':\": 12325,\n",
       " \"'كثر':\": 11793,\n",
       " \"'كل':\": 11732,\n",
       " \"'قرء':\": 11569,\n",
       " \"'وجد':\": 11393,\n",
       " \"'عمل':\": 11385,\n",
       " \"'لم':\": 11313,\n",
       " \"'وقع':\": 10642,\n",
       " '5,': 10607,\n",
       " \"'غير':\": 10025,\n",
       " \"'ندق':\": 9294,\n",
       " \"'بعد':\": 9224,\n",
       " \"'غرف':\": 9145,\n",
       " \"'جمل':\": 8904,\n",
       " \"'روي':\": 8738,\n",
       " \"'لكن':\": 8616,\n",
       " \"'مع':\": 8561,\n",
       " \"'حدث':\": 8098,\n",
       " \"'خدم':\": 8077,\n",
       " \"'نظف':\": 7907,\n",
       " \"'نفس':\": 7907,\n",
       " \"'علم':\": 7804,\n",
       " \"'جمع':\": 7229,\n",
       " \"'التي':\": 7228,\n",
       " \"'الل':\": 7046,\n",
       " \"'هو':\": 6993,\n",
       " \"'فكر':\": 6918,\n",
       " \"'شخص':\": 6779,\n",
       " \"'وحد':\": 6686,\n",
       " \"'قرب':\": 6616,\n",
       " \"'بعض':\": 6601,\n",
       " \"'عجب':\": 6543,\n",
       " \"'ولا':\": 6436,\n",
       " \"'كانت':\": 6341,\n",
       " \"'شكل':\": 6282,\n",
       " \"'عند':\": 6199,\n",
       " \"'كلم':\": 6178,\n",
       " \"'عرف':\": 6123,\n",
       " \"'اخر':\": 5959,\n",
       " \"'رءع':\": 5934,\n",
       " \"'حتى':\": 5912,\n",
       " \"'الا':\": 5863,\n",
       " \"'شيء':\": 5851,\n",
       " \"'قدم':\": 5827,\n",
       " \"'دخل':\": 5779,\n",
       " \"'بين':\": 5671,\n",
       " \"'هذه':\": 5606,\n",
       " \"'شعر':\": 5586,\n",
       " '6,': 5534,\n",
       " \"'سلب':\": 5350,\n",
       " \"'نظر':\": 5258,\n",
       " \"'الذي':\": 5171,\n",
       " \"'طرق':\": 5132,\n",
       " \"'نهي':\": 5043,\n",
       " \"'سيء':\": 4994,\n",
       " \"'علي':\": 4927,\n",
       " \"'وقف':\": 4907,\n",
       " \"'ليس':\": 4897,\n",
       " \"'جيد':\": 4798,\n",
       " \"'فقط':\": 4716,\n",
       " \"'عبر':\": 4641,\n",
       " \"'اول':\": 4620,\n",
       " \"'كبر':\": 4584,\n",
       " \"'عدم':\": 4483,\n",
       " \"'اي':\": 4393,\n",
       " \"'نسب':\": 4386,\n",
       " \"'فعل':\": 4347,\n",
       " \"'فضل':\": 4275,\n",
       " \"'خلف':\": 4245,\n",
       " \"'كنت':\": 4237,\n",
       " \"'حقق':\": 4215,\n",
       " \"'ولكن':\": 4198,\n",
       " \"'وصل':\": 4163,\n",
       " \"'فصل':\": 4112,\n",
       " \"'ذكر':\": 4111,\n",
       " \"'حرم':\": 4103,\n",
       " \"'نجم':\": 4083,\n",
       " \"'به':\": 4080,\n",
       " \"'ذلك':\": 4080,\n",
       " \"'وظف':\": 4025,\n",
       " \"'وقت':\": 4000,\n",
       " \"'هي':\": 3972,\n",
       " \"'خرج':\": 3970,\n",
       " \"'سلم':\": 3953,\n",
       " \"'انا':\": 3940,\n",
       " \"'بس':\": 3923,\n",
       " \"'شي':\": 3888,\n",
       " \"'طلب':\": 3793,\n",
       " \"'امل':\": 3758,\n",
       " \"'حمد':\": 3744,\n",
       " \"'رغم':\": 3728,\n",
       " \"'سبب':\": 3726,\n",
       " \"'حول':\": 3706,\n",
       " \"'بلغ':\": 3673,\n",
       " \"'قدر':\": 3669,\n",
       " \"'كمل':\": 3669,\n",
       " \"'متز':\": 3644,\n",
       " \"'جدد':\": 3625,\n",
       " \"'كما':\": 3575,\n",
       " \"'مثل':\": 3525,\n",
       " \"'له':\": 3513,\n",
       " \"'لو':\": 3513,\n",
       " \"'وضع':\": 3497,\n",
       " \"'بها':\": 3491,\n",
       " \"'سعر':\": 3467,\n",
       " \"'طعم':\": 3447,\n",
       " \"'فطر':\": 3413,\n",
       " \"'سير':\": 3411,\n",
       " \"'نصح':\": 3384,\n",
       " \"'مرة':\": 3373,\n",
       " \"'جعل':\": 3282,\n",
       " \"'لي':\": 3271,\n",
       " \"{'جيد':\": 3265,\n",
       " \"'قصة':\": 3254,\n",
       " \"'سحق':\": 3240,\n",
       " \"'صفح':\": 3225,\n",
       " \"'امر':\": 3203,\n",
       " \"'يكون':\": 3202,\n",
       " \"'قد':\": 3178,\n",
       " \"'مش':\": 3164,\n",
       " \"'طبع':\": 3121,\n",
       " \"'حية':\": 3051,\n",
       " \"'كيف':\": 3045,\n",
       " \"'صغر':\": 3039,\n",
       " \"'اقل':\": 3032,\n",
       " \"'متع':\": 3026,\n",
       " \"'عقد':\": 3023,\n",
       " \"'اني':\": 2997,\n",
       " \"'لءن':\": 2993,\n",
       " \"'خرى':\": 2969,\n",
       " '7,': 2946,\n",
       " \"{'ضعف':\": 2938,\n",
       " \"'دين':\": 2928,\n",
       " \"'بسط':\": 2927,\n",
       " \"'وصف':\": 2908,\n",
       " \"'عرب':\": 2904,\n",
       " \"'قيم':\": 2903,\n",
       " \"'بدء':\": 2902,\n",
       " \"'يوم':\": 2889,\n",
       " \"'غرب':\": 2882,\n",
       " \"'ولم':\": 2871,\n",
       " \"'كتر':\": 2852,\n",
       " \"'ضعف':\": 2851,\n",
       " \"'قلب':\": 2841,\n",
       " \"'طول':\": 2824,\n",
       " \"'منها':\": 2771,\n",
       " \"'سعد':\": 2756,\n",
       " \"'فهم':\": 2743,\n",
       " \"'عليه':\": 2739,\n",
       " \"'هناك':\": 2730,\n",
       " \"'سءل':\": 2722,\n",
       " \"'حيث':\": 2696,\n",
       " \"'علق':\": 2685,\n",
       " \"'حمل':\": 2674,\n",
       " \"'اذا':\": 2664,\n",
       " \"'الي':\": 2662,\n",
       " \"'اما':\": 2654,\n",
       " \"'منه':\": 2632,\n",
       " \"'لها':\": 2622,\n",
       " \"'عنه':\": 2618,\n",
       " \"'تكون':\": 2615,\n",
       " \"'جزء':\": 2615,\n",
       " \"'بدي':\": 2589,\n",
       " \"'رجل':\": 2576,\n",
       " \"'صدق':\": 2571,\n",
       " \"'حمم':\": 2564,\n",
       " \"'وجه':\": 2561,\n",
       " \"'نوع':\": 2558,\n",
       " \"'احد':\": 2550,\n",
       " \"'خير':\": 2541,\n",
       " \"'حكم':\": 2525,\n",
       " \"'عقل':\": 2522,\n",
       " \"'سرد':\": 2439,\n",
       " \"'طقم':\": 2426,\n",
       " \"'عرض':\": 2420,\n",
       " \"{'خيب':\": 2420,\n",
       " \"'فقد':\": 2417,\n",
       " \"'دفع':\": 2401,\n",
       " \"'حاج':\": 2399,\n",
       " \"'ريح':\": 2399,\n",
       " \"'ارخ':\": 2396,\n",
       " \"'حجز':\": 2394,\n",
       " \"{'ندق':\": 2387,\n",
       " \"'بل':\": 2378,\n",
       " \"'سرع':\": 2366,\n",
       " \"'بطل':\": 2365,\n",
       " \"'بءن':\": 2362,\n",
       " \"'ثلث':\": 2357,\n",
       " \"'دون':\": 2355,\n",
       " \"'كرر':\": 2353,\n",
       " \"'حال':\": 2350,\n",
       " \"'تلك':\": 2346,\n",
       " \"'يمكن':\": 2338,\n",
       " \"'وءن':\": 2335,\n",
       " \"'خلص':\": 2327,\n",
       " \"'ثني':\": 2301,\n",
       " \"'ناس':\": 2297,\n",
       " \"'صور':\": 2294,\n",
       " \"'ظهر':\": 2293,\n",
       " \"'جنب':\": 2284,\n",
       " \"{'روي':\": 2281,\n",
       " \"'انس':\": 2277,\n",
       " \"'وضح':\": 2274,\n",
       " \"'جرب':\": 2265,\n",
       " \"'قلل':\": 2265,\n",
       " \"'درج':\": 2262,\n",
       " \"'ايض':\": 2247,\n",
       " \"'ابد':\": 2242,\n",
       " \"'رحل':\": 2238,\n",
       " \"'ستى':\": 2231,\n",
       " \"'ثم':\": 2229,\n",
       " \"'بحث':\": 2221,\n",
       " \"'عدد':\": 2208,\n",
       " \"'لما':\": 2193,\n",
       " \"'زعج':\": 2172,\n",
       " \"'هدء':\": 2164,\n",
       " \"'انن':\": 2146,\n",
       " \"'اسف':\": 2143,\n",
       " \"'قصص':\": 2110,\n",
       " \"'مكن':\": 2110,\n",
       " \"'عظم':\": 2108,\n",
       " \"'شهد':\": 2107,\n",
       " \"'نقل':\": 2105,\n",
       " \"'حيت':\": 2094,\n",
       " \"'طفل':\": 2090,\n",
       " \"'سرر':\": 2087,\n",
       " \"'لحظ':\": 2085,\n",
       " \"'بشر':\": 2083,\n",
       " \"'خصص':\": 2071,\n",
       " \"'عمق':\": 2061,\n",
       " \"'قال':\": 2056,\n",
       " \"'ادب':\": 2050,\n",
       " \"'بكل':\": 2048,\n",
       " \"'دور':\": 2046,\n",
       " \"'مما':\": 2027,\n",
       " \"'وهو':\": 2010,\n",
       " \"'عليها':\": 2006,\n",
       " \"'صلح':\": 1999,\n",
       " \"'صرح':\": 1987,\n",
       " \"'فتح':\": 1983,\n",
       " \"'يا':\": 1975,\n",
       " \"'عنى':\": 1973,\n",
       " \"'خلل':\": 1954,\n",
       " \"'يقل':\": 1953,\n",
       " \"{'استثناءي':\": 1950,\n",
       " \"'لن':\": 1937,\n",
       " \"'؟':\": 1931,\n",
       " \"'يجب':\": 1930,\n",
       " \"'عام':\": 1927,\n",
       " \"'جرد':\": 1924,\n",
       " \"'اسم':\": 1920,\n",
       " \"'طلق':\": 1919,\n",
       " \"'صبح':\": 1918,\n",
       " \"'فتر':\": 1913,\n",
       " \"'كله':\": 1911,\n",
       " \"'عمر':\": 1884,\n",
       " \"'لغة':\": 1868,\n",
       " \"'وفر':\": 1868,\n",
       " \"'ايم':\": 1865,\n",
       " \"'ربع':\": 1857,\n",
       " \"'حد':\": 1843,\n",
       " \"'لزم':\": 1840,\n",
       " \"'ولى':\": 1839,\n",
       " \"'خلق':\": 1832,\n",
       " \"'حبب':\": 1831,\n",
       " \"'وفق':\": 1822,\n",
       " \"'شكر':\": 1820,\n",
       " \"'لحب':\": 1819,\n",
       " \"'ده':\": 1810,\n",
       " \"'هنا':\": 1809,\n",
       " '8,': 1798,\n",
       " \"'حضر':\": 1797,\n",
       " \"'حصل':\": 1792,\n",
       " \"'خمس':\": 1789,\n",
       " \"'زمن':\": 1788,\n",
       " \"'رجع':\": 1778,\n",
       " \"{'رءع':\": 1769,\n",
       " \"'يكن':\": 1759,\n",
       " \"{'لا':\": 1739,\n",
       " \"'زيد':\": 1731,\n",
       " \"'قرت':\": 1726,\n",
       " \"'نزل':\": 1726,\n",
       " \"'بقى':\": 1725,\n",
       " \"'رسل':\": 1724,\n",
       " \"'ولك':\": 1716,\n",
       " \"'روح':\": 1713,\n",
       " \"'حين':\": 1709,\n",
       " \"'غلب':\": 1699,\n",
       " \"'نهم':\": 1697,\n",
       " \"'ربم':\": 1692,\n",
       " \"'ومن':\": 1680,\n",
       " \"'بدع':\": 1678,\n",
       " \"'سمع':\": 1673,\n",
       " \"'فرق':\": 1671,\n",
       " \"'ليل':\": 1665,\n",
       " \"'حدد':\": 1662,\n",
       " \"'حسب':\": 1662,\n",
       " \"'سبق':\": 1652,\n",
       " \"'حجة':\": 1645,\n",
       " \"'حسن':\": 1633,\n",
       " \"'رفع':\": 1628,\n",
       " \"'ميز':\": 1627,\n",
       " \"'عبد':\": 1622,\n",
       " \"'وفي':\": 1613,\n",
       " \"'رءي':\": 1610,\n",
       " \"'شء':\": 1603,\n",
       " \"'خيل':\": 1594,\n",
       " \"'حفظ':\": 1593,\n",
       " \"'ف':\": 1588,\n",
       " \"'سكن':\": 1586,\n",
       " \"'رءح':\": 1584,\n",
       " \"'سهل':\": 1579,\n",
       " \"'صعب':\": 1574,\n",
       " \"'عءل':\": 1562,\n",
       " \"'قصر':\": 1559,\n",
       " \"'عدة':\": 1541,\n",
       " \"'ريه':\": 1539,\n",
       " \"'للى':\": 1537,\n",
       " \"'ذات':\": 1536,\n",
       " \"'اجد':\": 1534,\n",
       " \"'هل':\": 1523,\n",
       " \"'فرد':\": 1519,\n",
       " \"'شرع':\": 1506,\n",
       " \"'ملل':\": 1501,\n",
       " \"{'متز':\": 1498,\n",
       " \"'اصل':\": 1491,\n",
       " \"'عدي':\": 1487,\n",
       " \"'عين':\": 1480,\n",
       " \"'تصل':\": 1479,\n",
       " \"'وغر':\": 1479,\n",
       " \"'لكل':\": 1473,\n",
       " \"'اثث':\": 1470,\n",
       " \"'صحب':\": 1470,\n",
       " \"'كءن':\": 1470,\n",
       " \"'قطع':\": 1468,\n",
       " \"'ذهب':\": 1467,\n",
       " \"'ارض':\": 1466,\n",
       " \"'قرن':\": 1460,\n",
       " \"'حلة':\": 1458,\n",
       " \"'يتم':\": 1450,\n",
       " \"'ءثر':\": 1442,\n",
       " \"'بدن':\": 1442,\n",
       " \"'طبق':\": 1441,\n",
       " \"'كشف':\": 1441,\n",
       " \"'شوق':\": 1434,\n",
       " \"'يعن':\": 1431,\n",
       " \"'عشر':\": 1429,\n",
       " \"'تم':\": 1425,\n",
       " \"'حسس':\": 1421,\n",
       " \"'حلم':\": 1421,\n",
       " \"'وما':\": 1405,\n",
       " \"'لتى':\": 1402,\n",
       " \"'لهم':\": 1395,\n",
       " \"'خطء':\": 1394,\n",
       " \"'نصف':\": 1394,\n",
       " \"'عشن':\": 1389,\n",
       " \"'ولد':\": 1385,\n",
       " \"'ام':\": 1384,\n",
       " \"'طلع':\": 1383,\n",
       " \"'حور':\": 1381,\n",
       " \"'سبح':\": 1381,\n",
       " \"'منى':\": 1380,\n",
       " \"'قمة':\": 1376,\n",
       " \"'خصة':\": 1373,\n",
       " \"'درس':\": 1372,\n",
       " \"'لنا':\": 1371,\n",
       " \"'ارد':\": 1370,\n",
       " \"'ربط':\": 1366,\n",
       " \"'انت':\": 1362,\n",
       " \"'غية':\": 1353,\n",
       " \"'رءس':\": 1349,\n",
       " \"'عصر':\": 1349,\n",
       " \"'وكل':\": 1349,\n",
       " \"'بلد':\": 1346,\n",
       " \"'رحم':\": 1345,\n",
       " \"'وهذا':\": 1345,\n",
       " \"'خبر':\": 1335,\n",
       " \"'سيس':\": 1331,\n",
       " \"'ايه':\": 1327,\n",
       " \"'قتل':\": 1324,\n",
       " \"'لك':\": 1323,\n",
       " \"'تكن':\": 1315,\n",
       " \"'انك':\": 1311,\n",
       " \"'احب':\": 1303,\n",
       " \"'ءلف':\": 1302,\n",
       " \"'قرر':\": 1298,\n",
       " \"'مره':\": 1298,\n",
       " \"'كون':\": 1297,\n",
       " \"'فرض':\": 1290,\n",
       " \"'ظلم':\": 1287,\n",
       " \"'شدد':\": 1282,\n",
       " \"'شهر':\": 1281,\n",
       " \"'تما':\": 1268,\n",
       " \"'سوء':\": 1265,\n",
       " \"'لان':\": 1262,\n",
       " \"'وسع':\": 1261,\n",
       " \"'فهو':\": 1254,\n",
       " \"'واي':\": 1247,\n",
       " \"{'جمل':\": 1239,\n",
       " \"'اثر':\": 1237,\n",
       " \"'فاي':\": 1235,\n",
       " \"'نطق':\": 1230,\n",
       " \"'شبه':\": 1228,\n",
       " \"'/':\": 1227,\n",
       " \"'رقي':\": 1224,\n",
       " \"'قصد':\": 1219,\n",
       " \"'لسف':\": 1218,\n",
       " \"'سعة':\": 1216,\n",
       " \"'زوج':\": 1214,\n",
       " \"'عكس':\": 1214,\n",
       " \"'الم':\": 1211,\n",
       " \"'نظم':\": 1208,\n",
       " \"'دي':\": 1206,\n",
       " \"'اكل':\": 1201,\n",
       " \"'فءن':\": 1199,\n",
       " \"'عنو':\": 1197,\n",
       " \"'منذ':\": 1193,\n",
       " \"'همم':\": 1190,\n",
       " \"'بهذا':\": 1177,\n",
       " \"'تطع':\": 1176,\n",
       " \"'نشر':\": 1168,\n",
       " \"'تبع':\": 1167,\n",
       " \"'بلا':\": 1164,\n",
       " \"'وان':\": 1164,\n",
       " '9,': 1162,\n",
       " \"'تخل':\": 1160,\n",
       " \"'تغر':\": 1158,\n",
       " \"'قنع':\": 1156,\n",
       " \"'فرش':\": 1155,\n",
       " \"'بحر':\": 1152,\n",
       " \"'رغب':\": 1151,\n",
       " \"'سوى':\": 1148,\n",
       " \"'صدر':\": 1147,\n",
       " \"'سطر':\": 1145,\n",
       " \"'كده':\": 1144,\n",
       " \"'حزن':\": 1143,\n",
       " \"'ركز':\": 1142,\n",
       " \"'فجء':\": 1140,\n",
       " \"'بذل':\": 1138,\n",
       " \"'حرف':\": 1138,\n",
       " \"'وهي':\": 1136,\n",
       " \"'بما':\": 1135,\n",
       " \"'رءة':\": 1132,\n",
       " \"'يرد':\": 1129,\n",
       " \"'وجب':\": 1120,\n",
       " \"'نقد':\": 1117,\n",
       " \"'ضيق':\": 1109,\n",
       " \"'دبي':\": 1107,\n",
       " \"'تحت':\": 1106,\n",
       " \"'دول':\": 1104,\n",
       " \"'مصر':\": 1104,\n",
       " \"'جهد':\": 1103,\n",
       " \"'فلم':\": 1102,\n",
       " \"'وليس':\": 1101,\n",
       " \"'كره':\": 1099,\n",
       " \"'رسم':\": 1096,\n",
       " \"'اله':\": 1093,\n",
       " \"'ءكد':\": 1091,\n",
       " \"'نجح':\": 1091,\n",
       " \"'داء':\": 1083,\n",
       " \"'لمذ':\": 1083,\n",
       " \"{'لم':\": 1083,\n",
       " \"'بدل':\": 1070,\n",
       " \"'وكان':\": 1068,\n",
       " \"'كفي':\": 1067,\n",
       " \"'لحد':\": 1066,\n",
       " \"'معا':\": 1064,\n",
       " \"'هدف':\": 1064,\n",
       " \"'دكتور':\": 1063,\n",
       " \"'اى':\": 1062,\n",
       " \"'جلس':\": 1062,\n",
       " \"'وكء':\": 1061,\n",
       " \"'موت':\": 1060,\n",
       " \"'اليوم':\": 1058,\n",
       " \"'اسر':\": 1056,\n",
       " \"'وقد':\": 1056,\n",
       " \"'ءخذ':\": 1055,\n",
       " \"'لقد':\": 1055,\n",
       " \"'ءخر':\": 1053,\n",
       " \"'ب':\": 1053,\n",
       " \"'بدو':\": 1053,\n",
       " \"'صعد':\": 1050,\n",
       " \"'حلل':\": 1046,\n",
       " \"'دقق':\": 1044,\n",
       " \"'لحق':\": 1041,\n",
       " \"'معه':\": 1041,\n",
       " \"'يلم':\": 1040,\n",
       " \"'ثنء':\": 1039,\n",
       " \"'جذب':\": 1039,\n",
       " \"'احس':\": 1037,\n",
       " \"'نقط':\": 1036,\n",
       " \"'نعم':\": 1035,\n",
       " \"'فقر':\": 1034,\n",
       " \"'ثور':\": 1032,\n",
       " \"'كرم':\": 1032,\n",
       " \"'وطن':\": 1030,\n",
       " \"'لدي':\": 1027,\n",
       " \"'بنء':\": 1024,\n",
       " \"'الن':\": 1023,\n",
       " \"'اخذ':\": 1021,\n",
       " \"'تجد':\": 1017,\n",
       " \"'نول':\": 1017,\n",
       " \"'صوت':\": 1015,\n",
       " \"'جنس':\": 1014,\n",
       " \"'خلد':\": 1014,\n",
       " \"'ياه':\": 1014,\n",
       " \"'جهل':\": 1010,\n",
       " \"'نرن':\": 1010,\n",
       " \"'الذين':\": 1009,\n",
       " \"'حرب':\": 1009,\n",
       " \"'خطر':\": 1007,\n",
       " \"'قول':\": 1006,\n",
       " \"'ولو':\": 1005,\n",
       " \"'ماء':\": 1000,\n",
       " \"'قوة':\": 998,\n",
       " \"'ع':\": 996,\n",
       " \"'هى':\": 996,\n",
       " \"'جسد':\": 993,\n",
       " \"'شعب':\": 988,\n",
       " \"'عشق':\": 984,\n",
       " \"'خفف':\": 979,\n",
       " \"'ادر':\": 974,\n",
       " \"'يعد':\": 973,\n",
       " \"'حبك':\": 972,\n",
       " \"'حكي':\": 972,\n",
       " \"'تعد':\": 971,\n",
       " \"'قبس':\": 970,\n",
       " \"'ابن':\": 969,\n",
       " \"'اكن':\": 968,\n",
       " \"'عطف':\": 968,\n",
       " \"'ونا':\": 968,\n",
       " \"'تحل':\": 967,\n",
       " \"'نقص':\": 966,\n",
       " \"'فلا':\": 965,\n",
       " \"'حجم':\": 957,\n",
       " \"'ورق':\": 953,\n",
       " \"'نصر':\": 950,\n",
       " \"'ثقف':\": 944,\n",
       " \"'ليه':\": 943,\n",
       " \"'نحي':\": 938,\n",
       " \"'برد':\": 937,\n",
       " \"'ترك':\": 937,\n",
       " \"'انى':\": 933,\n",
       " \"'اهم':\": 928,\n",
       " \"'صنع':\": 928,\n",
       " \"'اعد':\": 926,\n",
       " \"'لمن':\": 926,\n",
       " \"'حب':\": 917,\n",
       " \"'حقا':\": 917,\n",
       " \"'سقط':\": 917,\n",
       " \"'شغل':\": 917,\n",
       " \"'سيد':\": 914,\n",
       " \"'بسم':\": 913,\n",
       " \"'جرء':\": 913,\n",
       " \"'ال':\": 912,\n",
       " \"'نوم':\": 912,\n",
       " \"'تقل':\": 910,\n",
       " \"'باب':\": 909,\n",
       " \"'امن':\": 906,\n",
       " \"'طرح':\": 906,\n",
       " \"'كم':\": 906,\n",
       " \"'بقي':\": 902,\n",
       " \"'كذلك':\": 900,\n",
       " \"'صحح':\": 899,\n",
       " \"'خاص':\": 896,\n",
       " \"'بءس':\": 891,\n",
       " \"'جهز':\": 889,\n",
       " \"'حلو':\": 889,\n",
       " \"'نتج':\": 889,\n",
       " \"'ل':\": 887,\n",
       " \"'ضفة':\": 884,\n",
       " \"'لهذا':\": 884,\n",
       " \"'شرف':\": 883,\n",
       " \"'صدم':\": 881,\n",
       " \"'بيت':\": 879,\n",
       " \"'تنع':\": 879,\n",
       " \"'عيش':\": 878,\n",
       " \"'ملك':\": 873,\n",
       " \"'تمز':\": 868,\n",
       " \"'اسء':\": 862,\n",
       " \"'عنا':\": 862,\n",
       " \"'ءسلوب':\": 861,\n",
       " \"'امم':\": 861,\n",
       " \"'حست':\": 860,\n",
       " \"'الف':\": 857,\n",
       " \"'سطع':\": 855,\n",
       " \"'روع':\": 853,\n",
       " \"'الءء':\": 852,\n",
       " \"'عدل':\": 852,\n",
       " \"'هما':\": 852,\n",
       " \"'احا':\": 851,\n",
       " \"'خصر':\": 851,\n",
       " \"'سطح':\": 851,\n",
       " \"'سلط':\": 850,\n",
       " \"'تدر':\": 849,\n",
       " \"'غلي':\": 849,\n",
       " \"'فشل':\": 847,\n",
       " \"'قعد':\": 844,\n",
       " \"'قسم':\": 843,\n",
       " \"'وسط':\": 843,\n",
       " \"'سحر':\": 839,\n",
       " \"'توقع':\": 838,\n",
       " \"'الذى':\": 833,\n",
       " \"'مرء':\": 831,\n",
       " \"'تعب':\": 830,\n",
       " \"'سفر':\": 830,\n",
       " \"'يصل':\": 827,\n",
       " \"'اجل':\": 826,\n",
       " \"'زير':\": 826,\n",
       " \"'صري':\": 825,\n",
       " \"'ولل':\": 823,\n",
       " \"'بوف':\": 822,\n",
       " \"'صرف':\": 817,\n",
       " \"'سمء':\": 816,\n",
       " \"'ساع':\": 815,\n",
       " \"'سبع':\": 808,\n",
       " \"'شبب':\": 808,\n",
       " \"'ورد':\": 808,\n",
       " \"'جبر':\": 807,\n",
       " \"'سلس':\": 806,\n",
       " \"'هم':\": 806,\n",
       " \"'عذب':\": 802,\n",
       " \"'نحن':\": 802,\n",
       " \"'سان':\": 800,\n",
       " \"'لمس':\": 798,\n",
       " \"'صنف':\": 797,\n",
       " \"'بجد':\": 794,\n",
       " \"'قام':\": 794,\n",
       " \"'رفض':\": 792,\n",
       " \"'عود':\": 792,\n",
       " \"'فيم':\": 791,\n",
       " \"'هكذ':\": 789,\n",
       " \"'دير':\": 788,\n",
       " \"'رتب':\": 781,\n",
       " \"'زي':\": 781,\n",
       " \"'وسف':\": 781,\n",
       " \"'سخر':\": 780,\n",
       " \"'عزل':\": 780,\n",
       " \"'ممل':\": 780,\n",
       " \"'سعه':\": 779,\n",
       " \"'بهر':\": 777,\n",
       " \"'طلل':\": 775,\n",
       " \"'عمد':\": 774,\n",
       " \"'وهم':\": 773,\n",
       " \"'فهي':\": 772,\n",
       " \"'كمن':\": 771,\n",
       " \"'شرح':\": 770,\n",
       " \"'بهذ':\": 768,\n",
       " \"'مول':\": 768,\n",
       " \"'صلة':\": 767,\n",
       " \"'بيه':\": 765,\n",
       " \"'تفق':\": 764,\n",
       " \"'حتي':\": 762,\n",
       " \"'ليء':\": 761,\n",
       " \"'علك':\": 758,\n",
       " \"'دى':\": 757,\n",
       " \"'لسل':\": 756,\n",
       " \"'نفذ':\": 756,\n",
       " \"'ثلا':\": 754,\n",
       " \"'جدر':\": 754,\n",
       " \"'رحة':\": 754,\n",
       " \"'غلف':\": 754,\n",
       " \"'يجد':\": 754,\n",
       " \"'نسء':\": 751,\n",
       " \"'ارى':\": 750,\n",
       " \"'لطف':\": 748,\n",
       " \"'بطء':\": 746,\n",
       " '2}': 742,\n",
       " \"'غرق':\": 740,\n",
       " \"'لعب':\": 736,\n",
       " \"'كذل':\": 735,\n",
       " \"'نهء':\": 734,\n",
       " \"'فوق':\": 733,\n",
       " \"'نقش':\": 733,\n",
       " \"'مجا':\": 731,\n",
       " \"'سمح':\": 730,\n",
       " \"'ريت':\": 728,\n",
       " \"'ملء':\": 728,\n",
       " \"'اهل':\": 723,\n",
       " \"'تعا':\": 720,\n",
       " \"'ورب':\": 720,\n",
       " \"'رجم':\": 719,\n",
       " \"'لنه':\": 719,\n",
       " \"'سجد':\": 718,\n",
       " \"'ورء':\": 718,\n",
       " \"'زلء':\": 715,\n",
       " \"'قمت':\": 715,\n",
       " \"'ملة':\": 715,\n",
       " \"'سنة':\": 713,\n",
       " \"'بصر':\": 711,\n",
       " \"'وعد':\": 710,\n",
       " \"'شرك':\": 708,\n",
       " '10,': 708,\n",
       " \"'شرق':\": 707,\n",
       " \"'عجز':\": 707,\n",
       " \"'نهى':\": 706,\n",
       " \"'قلت':\": 704,\n",
       " \"'دنا':\": 702,\n",
       " \"'لبس':\": 701,\n",
       " \"'صرع':\": 698,\n",
       " \"'سيح':\": 695,\n",
       " \"'والتي':\": 694,\n",
       " \"'ا':\": 693,\n",
       " \"'مني':\": 692,\n",
       " \"'ركب':\": 689,\n",
       " \"'ضرب':\": 688,\n",
       " \"'ولن':\": 687,\n",
       " \"'اظن':\": 685,\n",
       " \"'فيد':\": 685,\n",
       " \"'جوز':\": 682,\n",
       " \"'عمي':\": 682,\n",
       " \"'وكف':\": 682,\n",
       " \"'طيع':\": 681,\n",
       " \"'رفق':\": 680,\n",
       " \"'طرف':\": 680,\n",
       " \"'لذذ':\": 679,\n",
       " \"'طبخ':\": 677,\n",
       " \"'ريض':\": 676,\n",
       " \"'سمر':\": 672,\n",
       " \"'رعب':\": 671,\n",
       " \"'فرغ':\": 671,\n",
       " \"'وكن':\": 670,\n",
       " \"'اقر':\": 668,\n",
       " \"'يقم':\": 668,\n",
       " \"'شقق':\": 665,\n",
       " \"'شمل':\": 665,\n",
       " \"'فيش':\": 664,\n",
       " \"'انم':\": 660,\n",
       " \"'يعش':\": 660,\n",
       " \"'عمة':\": 659,\n",
       " \"'ظرف':\": 658,\n",
       " \"'قلد':\": 655,\n",
       " \"'لذلك':\": 652,\n",
       " \"'لهذ':\": 651,\n",
       " \"'يدر':\": 651,\n",
       " \"'سبل':\": 650,\n",
       " \"'يهم':\": 650,\n",
       " \"'بنت':\": 648,\n",
       " \"'منع':\": 648,\n",
       " \"'حجه':\": 646,\n",
       " \"'تعش':\": 644,\n",
       " \"'حرة':\": 644,\n",
       " \"'سجل':\": 643,\n",
       " \"'ضحك':\": 643,\n",
       " \"{'اول':\": 643,\n",
       " \"'لفظ':\": 642,\n",
       " \"'ومع':\": 642,\n",
       " \"'كوس':\": 640,\n",
       " \"'برر':\": 639,\n",
       " \"{'كان':\": 639,\n",
       " \"'اقم':\": 637,\n",
       " \"'وقل':\": 637,\n",
       " \"'رءت':\": 636,\n",
       " \"'رهب':\": 634,\n",
       " \"'مهم':\": 634,\n",
       " \"'بكر':\": 631,\n",
       " \"'فسد':\": 631,\n",
       " \"'اعط':\": 629,\n",
       " \"'رات':\": 628,\n",
       " \"'شاء':\": 628,\n",
       " \"'بشد':\": 625,\n",
       " \"'ردد':\": 622,\n",
       " \"'ضيف':\": 622,\n",
       " \"'طيب':\": 622,\n",
       " \"'عني':\": 620,\n",
       " \"'ورح':\": 617,\n",
       " \"'ه..':\": 616,\n",
       " \"'سء':\": 614,\n",
       " \"'شيخ':\": 614,\n",
       " \"'ولس':\": 614,\n",
       " \"'تشب':\": 612,\n",
       " \"'وخص':\": 612,\n",
       " \"'فرح':\": 611,\n",
       " \"'عبقر':\": 608,\n",
       " \"'غسل':\": 608,\n",
       " \"'لشي':\": 608,\n",
       " \"'عاد':\": 607,\n",
       " \"'عيب':\": 607,\n",
       " \"'تحس':\": 606,\n",
       " \"'جنح':\": 606,\n",
       " \"'خطب':\": 606,\n",
       " \"'لخص':\": 606,\n",
       " \"'عجبنى':\": 605,\n",
       " \"'فسر':\": 605,\n",
       " \"'قءم':\": 605,\n",
       " \"'شرب':\": 604,\n",
       " \"'برء':\": 601,\n",
       " \"'رضي':\": 600,\n",
       " \"'غدر':\": 595,\n",
       " \"'تصر':\": 594,\n",
       " \"'ندم':\": 594,\n",
       " \"'همة':\": 594,\n",
       " \"'نكر':\": 593,\n",
       " \"'دلل':\": 592,\n",
       " \"'لشء':\": 591,\n",
       " \"'لكم':\": 591,\n",
       " \"{'سيء':\": 591,\n",
       " \"'ريل':\": 590,\n",
       " \"'ساذ':\": 589,\n",
       " \"'تطر':\": 586,\n",
       " \"'رهق':\": 586,\n",
       " \"'،،':\": 585,\n",
       " \"'اسس':\": 585,\n",
       " \"'دا':\": 585,\n",
       " \"'نقض':\": 585,\n",
       " \"'عقب':\": 583,\n",
       " \"'فءد':\": 581,\n",
       " \"'وبين':\": 580,\n",
       " \"'سوق':\": 579,\n",
       " \"'عزز':\": 579,\n",
       " \"{'جرب':\": 579,\n",
       " \"'يحب':\": 578,\n",
       " \"'كسر':\": 577,\n",
       " \"'نبي':\": 577,\n",
       " \"'اكد':\": 576,\n",
       " \"'عها':\": 576,\n",
       " \"'بحج':\": 575,\n",
       " \"'سنو':\": 575,\n",
       " \"'قلم':\": 574,\n",
       " \"{'قرء':\": 574,\n",
       " \"'دهش':\": 573,\n",
       " \"'نور':\": 572,\n",
       " \"'توفر':\": 571,\n",
       " \"'وكانت':\": 570,\n",
       " \"'عيز':\": 569,\n",
       " \"'ءلم':\": 567,\n",
       " \"'هرب':\": 566,\n",
       " \"'بهم':\": 564,\n",
       " \"'شجع':\": 564,\n",
       " \"'ضيع':\": 564,\n",
       " \"'ترى':\": 563,\n",
       " \"'شوة':\": 562,\n",
       " \"'صطفى':\": 562,\n",
       " \"'نسى':\": 562,\n",
       " \"'هند':\": 562,\n",
       " \"'دار':\": 561,\n",
       " \"'درة':\": 561,\n",
       " \"'سوف':\": 560,\n",
       " \"'عما':\": 560,\n",
       " \"'ءمل':\": 559,\n",
       " \"'صين':\": 558,\n",
       " \"'حرر':\": 557,\n",
       " \"'حرق':\": 557,\n",
       " \"'ساح':\": 557,\n",
       " \"'لكي':\": 557,\n",
       " \"'تهل':\": 556,\n",
       " \"'ريب':\": 556,\n",
       " \"'اين':\": 555,\n",
       " \"'حشر':\": 555,\n",
       " \"'تقم':\": 552,\n",
       " \"'احي':\": 551,\n",
       " \"'جاء':\": 551,\n",
       " \"'عمو':\": 551,\n",
       " \"'نجب':\": 551,\n",
       " \"'طاع':\": 548,\n",
       " \"'ضمن':\": 546,\n",
       " \"'يمك':\": 546,\n",
       " \"'يسر':\": 545,\n",
       " \"{'وقع':\": 544,\n",
       " \"'كءب':\": 542,\n",
       " \"'قدس':\": 541,\n",
       " \"'غلق':\": 539,\n",
       " \"'قصه':\": 538,\n",
       " \"'غمض':\": 536,\n",
       " \"'جود':\": 535,\n",
       " \"'رمز':\": 535,\n",
       " \"'سجن':\": 535,\n",
       " \"'لسط':\": 535,\n",
       " \"'تني':\": 534,\n",
       " \"'سسي':\": 534,\n",
       " \"'اوي':\": 533,\n",
       " \"'مرت':\": 533,\n",
       " \"'حرك':\": 531,\n",
       " \"'ءمام':\": 530,\n",
       " \"'راد':\": 530,\n",
       " \"'قضة':\": 529,\n",
       " \"'لنص':\": 528,\n",
       " \"'مدى':\": 527,\n",
       " \"'ممر':\": 527,\n",
       " \"'بقة':\": 526,\n",
       " \"'حيل':\": 525,\n",
       " \"'فلس':\": 524,\n",
       " \"'نسي':\": 524,\n",
       " \"'ثير':\": 523,\n",
       " \"'وجع':\": 523,\n",
       " \"'وكم':\": 522,\n",
       " \"'بان':\": 521,\n",
       " \"'حبت':\": 521,\n",
       " \"'عنصر':\": 521,\n",
       " \"'نبه':\": 521,\n",
       " \"'وتم':\": 521,\n",
       " \"'بتع':\": 520,\n",
       " \"'مرض':\": 520,\n",
       " \"'حتج':\": 519,\n",
       " \"'مال':\": 519,\n",
       " \"'حق':\": 517,\n",
       " \"'فخم':\": 517,\n",
       " \"'لغي':\": 517,\n",
       " \"'هتم':\": 517,\n",
       " \"'حلي':\": 516,\n",
       " \"'زحم':\": 516,\n",
       " \"'لسن':\": 516,\n",
       " \"'شقة':\": 515,\n",
       " \"'طهر':\": 515,\n",
       " \"'فين':\": 515,\n",
       " \"'ترد':\": 512,\n",
       " \"'فتة':\": 510,\n",
       " \"'برع':\": 508,\n",
       " \"'تجه':\": 508,\n",
       " \"'وهن':\": 508,\n",
       " \"'يمل':\": 508,\n",
       " \"{'اسء':\": 508,\n",
       " \"'ادي':\": 507,\n",
       " \"'لبد':\": 507,\n",
       " \"{'انا':\": 507,\n",
       " \"'ءمر':\": 506,\n",
       " \"'حله':\": 506,\n",
       " \"'شاب':\": 506,\n",
       " \"'ثمن':\": 505,\n",
       " \"'خلط':\": 505,\n",
       " \"'خوف':\": 505,\n",
       " \"'سخف':\": 503,\n",
       " \"'جد،':\": 502,\n",
       " \"'لفت':\": 502,\n",
       " \"'لمح':\": 500,\n",
       " \"'ضرر':\": 498,\n",
       " \"'كنا':\": 497,\n",
       " \"{'قمة':\": 497,\n",
       " \"'لمد':\": 496,\n",
       " \"'لفز':\": 495,\n",
       " \"'صمم':\": 494,\n",
       " \"'وحس':\": 494,\n",
       " \"'خيب':\": 492,\n",
       " \"'رضى':\": 492,\n",
       " \"'تمس':\": 491,\n",
       " \"'حقب':\": 491,\n",
       " \"'يقع':\": 491,\n",
       " \"'تحب':\": 489,\n",
       " \"'عذر':\": 488,\n",
       " '11,': 487,\n",
       " \"'جرم':\": 486,\n",
       " \"'لعل':\": 486,\n",
       " \"'صبر':\": 485,\n",
       " \"'قذر':\": 485,\n",
       " \"'اشء':\": 484,\n",
       " \"'منا':\": 484,\n",
       " \"'نفع':\": 482,\n",
       " \"'شرط':\": 481,\n",
       " \"'كذب':\": 481,\n",
       " \"'ردء':\": 480,\n",
       " \"'صدف':\": 480,\n",
       " \"'نسخ':\": 480,\n",
       " \"'يلق':\": 480,\n",
       " \"'ابو':\": 478,\n",
       " \"'بي':\": 478,\n",
       " \"'غلط':\": 476,\n",
       " \"'لول':\": 474,\n",
       " \"'اوى':\": 473,\n",
       " \"'حوي':\": 473,\n",
       " \"'راهيم':\": 473,\n",
       " \"'بلل':\": 471,\n",
       " \"'رور':\": 471,\n",
       " \"'قيد':\": 471,\n",
       " \"'علش':\": 470,\n",
       " \"'قمه':\": 470,\n",
       " \"'ازل':\": 469,\n",
       " \"'بنى':\": 469,\n",
       " \"'قهر':\": 469,\n",
       " \"'وهب':\": 469,\n",
       " \"'بوب':\": 468,\n",
       " \"'ذتي':\": 467,\n",
       " \"'مواضيع':\": 467,\n",
       " \"'الس':\": 465,\n",
       " \"'جيل':\": 465,\n",
       " \"'جال':\": 464,\n",
       " \"'عشت':\": 464,\n",
       " \"'ارع':\": 463,\n",
       " \"'لءم':\": 462,\n",
       " \"'والذي':\": 462,\n",
       " \"'اضي':\": 461,\n",
       " \"'قرءء':\": 461,\n",
       " \"'وعن':\": 461,\n",
       " \"'يهد':\": 461,\n",
       " \"'دعو':\": 460,\n",
       " \"'لله':\": 460,\n",
       " \"'وحش':\": 460,\n",
       " \"'خار':\": 459,\n",
       " \"'عهد':\": 459,\n",
       " \"'كلف':\": 457,\n",
       " \"'ندر':\": 457,\n",
       " \"'رحب':\": 455,\n",
       " \"'عطل':\": 455,\n",
       " ...}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"There are %d Unique words:\"%len(unique_dict))\n",
    "unique_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>{'متز': 1, 'نوع': 1, 'ما': 1, 'نظف': 1, 'وقع':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>{'احد': 1, 'سبب': 1, 'نجح': 1, 'امر': 2, 'كل':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>{'هدف': 1, 'نقل': 1, 'صخب': 1, 'شرع': 1, 'قهر'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>{'خلص': 3, 'بدء': 1, 'الل': 1, 'بهر': 1, 'زي':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>{'ياس': 1, 'جزء': 2, 'لا': 2, 'دبي': 1, 'ندق':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66661</th>\n",
       "      <td>0</td>\n",
       "      <td>{'عرفش': 1, 'ليه': 1, 'كنت': 1, 'كمل': 1, 'وهي...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66662</th>\n",
       "      <td>0</td>\n",
       "      <td>{'لا': 3, 'سحق': 1, 'يكون': 1, 'كنق': 1, 'لنه'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66663</th>\n",
       "      <td>0</td>\n",
       "      <td>{'ضعف': 1, 'جدا': 1, 'ولم': 1, 'متع': 1, 'به':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66664</th>\n",
       "      <td>0</td>\n",
       "      <td>{'ملة': 1, 'جدا': 1, 'حمد': 1, 'حسن': 1, 'علو'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66665</th>\n",
       "      <td>0</td>\n",
       "      <td>{'لن': 1, 'رجع': 1, 'اله': 1, 'مرة': 1, 'خرى':...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66666 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                               freq\n",
       "0          1  {'متز': 1, 'نوع': 1, 'ما': 1, 'نظف': 1, 'وقع':...\n",
       "1          1  {'احد': 1, 'سبب': 1, 'نجح': 1, 'امر': 2, 'كل':...\n",
       "2          1  {'هدف': 1, 'نقل': 1, 'صخب': 1, 'شرع': 1, 'قهر'...\n",
       "3          1  {'خلص': 3, 'بدء': 1, 'الل': 1, 'بهر': 1, 'زي':...\n",
       "4          1  {'ياس': 1, 'جزء': 2, 'لا': 2, 'دبي': 1, 'ندق':...\n",
       "...      ...                                                ...\n",
       "66661      0  {'عرفش': 1, 'ليه': 1, 'كنت': 1, 'كمل': 1, 'وهي...\n",
       "66662      0  {'لا': 3, 'سحق': 1, 'يكون': 1, 'كنق': 1, 'لنه'...\n",
       "66663      0  {'ضعف': 1, 'جدا': 1, 'ولم': 1, 'متع': 1, 'به':...\n",
       "66664      0  {'ملة': 1, 'جدا': 1, 'حمد': 1, 'حسن': 1, 'علو'...\n",
       "66665      0  {'لن': 1, 'رجع': 1, 'اله': 1, 'مرة': 1, 'خرى':...\n",
       "\n",
       "[66666 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/youssef/.local/lib/python3.8/site-packages/pandas/core/frame.py:3607: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._set_item(key, value)\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "#converting string dict to dict\n",
    "df_copy['freq']=df_copy['freq'].apply(lambda x: ast.literal_eval(x))\n",
    "print(type(df_copy.head()[\"freq\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>freq</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>{'متز': 1, 'نوع': 1, 'ما': 1, 'نظف': 1, 'وقع':...</td>\n",
       "      <td>متز نوع ما نظف وقع جهز شاطيء طعم</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>{'احد': 1, 'سبب': 1, 'نجح': 1, 'امر': 2, 'كل':...</td>\n",
       "      <td>احد سبب نجح امر كل شخص هذه دول عشق ترب نحن نحب...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>{'هدف': 1, 'نقل': 1, 'صخب': 1, 'شرع': 1, 'قهر'...</td>\n",
       "      <td>هدف نقل صخب شرع قهر هدء جبل شيش عرف حقق ما جرى...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>{'خلص': 3, 'بدء': 1, 'الل': 1, 'بهر': 1, 'زي':...</td>\n",
       "      <td>خلص بدء الل بهر زي فيل زرق حمد راد خطى رحل قرء...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>{'ياس': 1, 'جزء': 2, 'لا': 2, 'دبي': 1, 'ندق':...</td>\n",
       "      <td>ياس جزء لا دبي ندق كامل خدم ريح نفس وجد</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66661</th>\n",
       "      <td>0</td>\n",
       "      <td>{'عرفش': 1, 'ليه': 1, 'كنت': 1, 'كمل': 1, 'وهي...</td>\n",
       "      <td>عرفش ليه كنت كمل وهي مش عجب حدث بطء ممل روي اط...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66662</th>\n",
       "      <td>0</td>\n",
       "      <td>{'لا': 3, 'سحق': 1, 'يكون': 1, 'كنق': 1, 'لنه'...</td>\n",
       "      <td>لا سحق يكون كنق لنه سيء شي وجد خدم فطر صبح ستي...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66663</th>\n",
       "      <td>0</td>\n",
       "      <td>{'ضعف': 1, 'جدا': 1, 'ولم': 1, 'متع': 1, 'به':...</td>\n",
       "      <td>ضعف جدا ولم متع به كل قصه سرد لحل شهد بدن فكر</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66664</th>\n",
       "      <td>0</td>\n",
       "      <td>{'ملة': 1, 'جدا': 1, 'حمد': 1, 'حسن': 1, 'علو'...</td>\n",
       "      <td>ملة جدا حمد حسن علو فنن وصف عند دقق حد ثني قرء...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66665</th>\n",
       "      <td>0</td>\n",
       "      <td>{'لن': 1, 'رجع': 1, 'اله': 1, 'مرة': 1, 'خرى':...</td>\n",
       "      <td>لن رجع اله مرة خرى قرب بحر كان قدم ولا وجد خدم...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66666 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                               freq  \\\n",
       "0          1  {'متز': 1, 'نوع': 1, 'ما': 1, 'نظف': 1, 'وقع':...   \n",
       "1          1  {'احد': 1, 'سبب': 1, 'نجح': 1, 'امر': 2, 'كل':...   \n",
       "2          1  {'هدف': 1, 'نقل': 1, 'صخب': 1, 'شرع': 1, 'قهر'...   \n",
       "3          1  {'خلص': 3, 'بدء': 1, 'الل': 1, 'بهر': 1, 'زي':...   \n",
       "4          1  {'ياس': 1, 'جزء': 2, 'لا': 2, 'دبي': 1, 'ندق':...   \n",
       "...      ...                                                ...   \n",
       "66661      0  {'عرفش': 1, 'ليه': 1, 'كنت': 1, 'كمل': 1, 'وهي...   \n",
       "66662      0  {'لا': 3, 'سحق': 1, 'يكون': 1, 'كنق': 1, 'لنه'...   \n",
       "66663      0  {'ضعف': 1, 'جدا': 1, 'ولم': 1, 'متع': 1, 'به':...   \n",
       "66664      0  {'ملة': 1, 'جدا': 1, 'حمد': 1, 'حسن': 1, 'علو'...   \n",
       "66665      0  {'لن': 1, 'رجع': 1, 'اله': 1, 'مرة': 1, 'خرى':...   \n",
       "\n",
       "                                                    text  \n",
       "0                       متز نوع ما نظف وقع جهز شاطيء طعم  \n",
       "1      احد سبب نجح امر كل شخص هذه دول عشق ترب نحن نحب...  \n",
       "2      هدف نقل صخب شرع قهر هدء جبل شيش عرف حقق ما جرى...  \n",
       "3      خلص بدء الل بهر زي فيل زرق حمد راد خطى رحل قرء...  \n",
       "4                ياس جزء لا دبي ندق كامل خدم ريح نفس وجد  \n",
       "...                                                  ...  \n",
       "66661  عرفش ليه كنت كمل وهي مش عجب حدث بطء ممل روي اط...  \n",
       "66662  لا سحق يكون كنق لنه سيء شي وجد خدم فطر صبح ستي...  \n",
       "66663      ضعف جدا ولم متع به كل قصه سرد لحل شهد بدن فكر  \n",
       "66664  ملة جدا حمد حسن علو فنن وصف عند دقق حد ثني قرء...  \n",
       "66665  لن رجع اله مرة خرى قرب بحر كان قدم ولا وجد خدم...  \n",
       "\n",
       "[66666 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#joined words into a sentence again to use sklearn model\n",
    "\n",
    "df_copy[\"text\"]=df_copy[\"freq\"].apply(lambda freq_dict: ' '.join(list(freq_dict.keys())) )\n",
    "df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  (46666,) (46666, 1) Test:  ((20000,), (20000, 1))\n"
     ]
    }
   ],
   "source": [
    "#Splitting data\n",
    "x=df_copy['text']\n",
    "y=np.expand_dims(df_copy['label'],axis=1)\n",
    "X_train,X_test,Y_train, Y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "print(\"Train: \" ,X_train.shape,Y_train.shape,\"Test: \",(X_test.shape,Y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer= TfidfVectorizer()\n",
    "tf_x_train = vectorizer.fit_transform(X_train)\n",
    "tf_x_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3054)\t0.399087852883007\n",
      "  (0, 530)\t0.34295341672047236\n",
      "  (0, 1238)\t0.3213888542967605\n",
      "  (0, 3274)\t0.27977113661028613\n",
      "  (0, 3322)\t0.3532507371589668\n",
      "  (0, 2397)\t0.3197743819705713\n",
      "  (0, 3140)\t0.23655315983481154\n",
      "  (0, 1253)\t0.19516641960193287\n",
      "  (0, 1683)\t0.3833121697914325\n",
      "  (0, 3361)\t0.17187081033107315\n",
      "  (0, 2709)\t0.15743661547652255\n",
      "  (0, 2717)\t0.1385857309095193\n"
     ]
    }
   ],
   "source": [
    "print(tf_x_train[1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#SVM\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "#NN\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "import sklearn.model_selection as modsel\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = ['precision_macro', 'recall_macro','f1_macro','accuracy'] #used for CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_scores_to_df(scores):\n",
    "    df=pd.DataFrame(scores)\n",
    "    df.drop(columns=['fit_time','score_time'],inplace=True)\n",
    "    return df\n",
    "def display_heatmap(y_test,pred):\n",
    "    matrix=confusion_matrix(y_test,pred)\n",
    "    sns.heatmap(matrix,annot=True)\n",
    "def print_cv_scores(scores):\n",
    "    scores_df=convert_scores_to_df(scores)\n",
    "    print(scores_df)\n",
    "    print(\"Means:-\\n\",scores_df.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nerual Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdamOptimizer:\n",
    "    def __init__(self,beta1,beta2,alpha,eps=10e-8):\n",
    "#         self.params=params\n",
    "#         self.n_iter=n_iter\n",
    "        self.beta1=beta1\n",
    "        self.beta2=beta2\n",
    "        self.alpha=alpha\n",
    "        self.eps=eps\n",
    "        self.ms=[]\n",
    "        self.vs=[]\n",
    "        \n",
    "    def reset_params(self,layers):\n",
    "        self.ms=[ \n",
    "                  [np.zeros_like(layer.W,dtype=np.float64), np.zeros_like(layer.b,dtype=np.float64)] \n",
    "                  for layer in layers      \n",
    "                 ]\n",
    "        self.vs=[ \n",
    "                  [np.zeros_like(layer.W,dtype=np.float64), np.zeros_like(layer.b,dtype=np.float64)] \n",
    "                  for layer in layers      \n",
    "                 ]\n",
    "#         print(\"vs:\",self.vs[0][0])\n",
    "        \n",
    "    def update(self,layers,N):\n",
    "#         print(self.vs[0][0])\n",
    "        for i in range(len(layers)):\n",
    "#             print(\"i:\",i)\n",
    "#             print(\"vs part1: \",self.vs[i][0])\n",
    "#             print(\"beta2:\",self.beta2)\n",
    "            self.ms[i][0]= self.beta1*self.ms[i][0]+(1.0-self.beta1)*layers[i].dW\n",
    "            self.ms[i][1]= self.beta1*self.ms[i][1]+(1.0-self.beta1)*layers[i].db\n",
    "            \n",
    "#             print(\"before: vs of\",i,\" = \", self.vs[i][0])\n",
    "            self.vs[i][0]= self.beta2*self.vs[i][0]+(1.0-self.beta2)*np.square(layers[i].dW)\n",
    "            self.vs[i][1]= self.beta2*self.vs[i][1]+(1.0-self.beta2)*np.square(layers[i].db)\n",
    "#             print(\"after: vs of\",i,\" = \", self.vs[i][0])\n",
    "\n",
    "#             print(\"vs:\",self.vs[i][0])\n",
    "#             print(\"eps:\", self.eps)\n",
    "            denDW= np.sqrt((self.vs[i][0] + self.eps))\n",
    "            denB=(np.sqrt((self.vs[i][1] + self.eps)))\n",
    "            \n",
    "            numDW=(-1 * self.alpha * self.ms[i][0])\n",
    "            numB=(-1 * self.alpha * self.ms[i][1])\n",
    "                    \n",
    "            deltaW = np.array(numDW /denDW ,dtype=np.float64)\n",
    "            deltab = np.array( numB/ denB  ,dtype=np.float64)\n",
    "        \n",
    "#             print(\"deltaW\",deltaW)\n",
    "#             print(\"deltab\",deltab)\n",
    "            layers[i].W +=  deltaW/np.sqrt(N)\n",
    "            layers[i].b +=  deltab/np.sqrt(N)\n",
    "        \n",
    "# class GradientDescent:\n",
    "#     def __init__(self,alpha):\n",
    "#         self.alpha=alpha\n",
    "#     def reset_params(self,layers):\n",
    "#         pass\n",
    "#     def update(self,layers,N):\n",
    "#         for i in range(len(layers)):\n",
    "#             # layers[i].dW=layers[i].dW/N\n",
    "#             # layers[i].db=layers[i].db/N\n",
    "#             layers[i].W = layers[i].W - self.alpha * (layers[i].dW/N)\n",
    "#             layers[i].b = layers[i].b - self.alpha * (layers[i].db/N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "\n",
    "class Layer:\n",
    "    \n",
    "    ### activations\n",
    "    def _relu(self,z):\n",
    "        return np.maximum(0,z)\n",
    "    def _diff_relu(self,z):\n",
    "        dZ=np.array(z,copy=True)\n",
    "        dZ[dZ<=0]=0\n",
    "        dZ[dZ>0]=1\n",
    "        return dZ\n",
    "    \n",
    "    def _identity(self,z):\n",
    "        return z\n",
    "    \n",
    "    def _identity_diff(self,z):\n",
    "        return np.ones_like(z)\n",
    "    \n",
    "    def _sigmoid(self,z):\n",
    "        return (1/(1+np.exp(-1*z)))\n",
    "\n",
    "    def _diff_sigmoid(self,z):\n",
    "        return self._sigmoid(z)*(1-self._sigmoid(z))\n",
    "    \n",
    "    def _softmax(self,z):\n",
    "        expZ= np.exp(z-np.max(z))\n",
    "        return expZ/expZ.sum(axis=0, keepdims=True)\n",
    "    def _diff_softmax(self,z):\n",
    "        pass\n",
    "\n",
    "    \n",
    "    ###########\n",
    "\n",
    "    def __init__(self,n_input,n_output, activation=\"identity\",name=None):\n",
    "        self.n_output= n_output\n",
    "        self.n_input= n_input\n",
    "        self.name= name\n",
    "        \n",
    "        if activation == \"identity\":\n",
    "            self.activation = self._identity\n",
    "            self.diff_act= self._identity_diff\n",
    "        \n",
    "        elif activation == \"sigmoid\":\n",
    "            self.activation = self._sigmoid\n",
    "            self.diff_act= self._diff_sigmoid\n",
    "            \n",
    "        elif activation == \"softmax\":\n",
    "            self.activation=self._softmax\n",
    "            self.diff_act=self._diff_softmax\n",
    "        elif activation ==\"relu\":\n",
    "            self.activation=self._relu\n",
    "            self.diff_act=self._diff_relu\n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "        self.W= np.random.randn(self.n_output,self.n_input)*np.sqrt(2/self.n_input)\n",
    "        self.b= np.random.randn(self.n_output,1)*np.sqrt(2/self.n_input)\n",
    "\n",
    "        self.dW= np.zeros_like(self.W)\n",
    "        self.db= np.zeros_like(self.b)\n",
    "        \n",
    "        self.Z= None\n",
    "        self.Ai = None\n",
    "    def print_shapes(self):\n",
    "        print(\"W: \",self.W.shape)\n",
    "        print(\"b: \",self.b.shape)\n",
    "    \n",
    "    def forward(self,Ai): #data dim \n",
    "\n",
    "        z =  np.add((self.W @ Ai),self.b)\n",
    "        A = self.activation(z)\n",
    "\n",
    "        \n",
    "        self.Z = z\n",
    "        self.Ai = Ai\n",
    "        return A\n",
    "    \n",
    "    \n",
    "    def backward(self,inp):\n",
    "        \n",
    "#         print(\"input shape: \",end='')\n",
    "#         print(inp.shape)\n",
    "       \n",
    "        act_diff = self.diff_act(self.Z)\n",
    "#         print(\"act_diff shape: \",end='')\n",
    "#         print(act_diff.shape)\n",
    "        \n",
    "        tmp = inp * act_diff\n",
    "#         print(\"tmp shape: \",end='')\n",
    "#         print(tmp.shape)\n",
    "        \n",
    "        bet = tmp @ self.Ai.T # vector of 1s\n",
    "#         print(\"bet shape: \",end='')\n",
    "#         print(bet.shape)\n",
    "        \n",
    "        \n",
    "        e = np.ones((self.Ai.shape[1],1))\n",
    "        db = tmp @ e\n",
    "#         print(\"db shape: \",end='')\n",
    "#         print(db.shape)\n",
    "        self.dW = (self.dW + bet)\n",
    "#         print(\"dw:\",self.dW.shape,\"\\nlen:\",len(self.dW))\n",
    "        self.db = self.db + db\n",
    "        \n",
    "        \n",
    "        return self.W.T @ tmp\n",
    "    \n",
    "    def print_weights(self):\n",
    "        print(\"\\n###################\")\n",
    "        if(self.name):\n",
    "            print(\"name: \",self.name)\n",
    "        print(\"dW: \",self.dW, \"W: \",self.W)\n",
    "    \n",
    "    def zeroing_delta(self):\n",
    "        self.dW= np.zeros_like(self.W)\n",
    "        self.db= np.zeros_like(self.b)\n",
    "\n",
    "\n",
    "class NN:\n",
    "    \n",
    "    ########\n",
    "    ## losses\n",
    "    def _MSE(self,y,yhat):\n",
    "        a=np.square(yhat-y)\n",
    "        a=np.sum(a)\n",
    "        b= 1/(2*y.shape[1])\n",
    "        return a*b\n",
    "\n",
    "    ## diff losses\n",
    "    def _diff_MSE(self,y,yhat,X):\n",
    "        return (yhat-y)\n",
    "    \n",
    "    def _binary_cross_entropy(self,y,yhat):\n",
    "#         print(\"inside bin cross entropy\\n\")\n",
    "        arr= -(y*np.log(yhat)+(1-y)*np.log(1-yhat))\n",
    "#         print(\"arr:\",arr)\n",
    "        return arr.mean()\n",
    "        \n",
    "    def _diff_binary_cross_entropy(self,y,yhat,X):\n",
    "#         print(\"X shape: \",X.shape)\n",
    "#         print(\"y shape: \",y.shape)\n",
    "#         print(\"y hat shape: \",yhat.shape)\n",
    "        dl_dyhat= -(y/yhat - (1-y)/(1-yhat))\n",
    "#         loss= X.T @ (yhat - y)\n",
    "#         print(\"dl_dyhat:\",dl_dyhat)\n",
    "        return dl_dyhat\n",
    "    \n",
    "    #########\n",
    "    \n",
    "    def __init__(self,optimizer,loss=\"binary_cross\"):\n",
    "        self.layers = []\n",
    "        self.optimizer=optimizer\n",
    "        self.loss_name=loss\n",
    "        self.initialize_loss();\n",
    "    \n",
    "   \n",
    "    def initialize_loss(self): \n",
    "        if(self.loss_name==\"binary_cross\"):\n",
    "            self.loss=self._binary_cross_entropy\n",
    "            self.loss_diff=self._diff_binary_cross_entropy\n",
    "        elif self.loss_name==\"MSE\":\n",
    "            self.loss=self._MSE\n",
    "            self.loss_diff=self._diff_MSE\n",
    "        \n",
    "    \n",
    " \n",
    "    \n",
    "    def forward(self,x_train):\n",
    "        a=x_train\n",
    "        for layer in self.layers:\n",
    "            a = layer.forward(a)\n",
    "        return a\n",
    "    \n",
    "    def backward(self,input):\n",
    "        gd = input\n",
    "        for layer in self.layers[::-1]:\n",
    "            gd = layer.backward(gd)\n",
    "            \n",
    "    def add_layer(self,n_input,n_output, activation=\"identity\",name=None):\n",
    "        self.layers.append(Layer(n_input,n_output, activation=activation,name=name))\n",
    "        \n",
    "    def fit(self, x_train,y_train, epochs=5): #data dim is MxN .. M no of examples.. N no of dimension\n",
    "        \n",
    "        M = x_train.shape[0]\n",
    "        \n",
    "        \n",
    "        x_train = x_train.T\n",
    "        y_train = y_train.T\n",
    "        \n",
    "        self.optimizer.reset_params(self.layers)\n",
    "        \n",
    "        for i in range(epochs):\n",
    "            print(\"Epoche {}/{}\".format(i+1,epochs))\n",
    "            y_hat= self.forward(x_train)\n",
    "            \n",
    "            dl_dyhat = self.loss_diff(y_train,y_hat,self.layers[-1].Ai)\n",
    "            loss=self.loss(y_train,y_hat)\n",
    "            print(\"loss=\",loss)\n",
    "\n",
    "            \n",
    "            self.backward(dl_dyhat)\n",
    "#             print(\"Before update vs=\",self.optimizer.vs[0][0])\n",
    "            self.optimizer.update(self.layers,M)\n",
    "#             self.print_weights()\n",
    "            \n",
    "            # zeroing deltas\n",
    "            for layer in self.layers:\n",
    "                layer.zeroing_delta()\n",
    "            \n",
    "        print(\"Finished....\") \n",
    "            \n",
    "            \n",
    "        \n",
    "\n",
    "    \n",
    "    def predict(self,x_test): #data dim is NxD .. N no of examples.. D no of dimension\n",
    "        print(\"x_test:\", x_test.shape)\n",
    "        y_hat= self.forward(x_test.T).T\n",
    "        return y_hat\n",
    "#         print(y_hat)\n",
    "#         y_hat[y_hat>0.5]=1\n",
    "#         y_hat[y_hat<=0.5]=0\n",
    "#         return y_hat\n",
    "                    \n",
    "    def print_weights(self):\n",
    "        for i in range(len(self.layers)):\n",
    "            print(\"layer i= \",i,end=\" \")\n",
    "            self.layers[i].print_weights()\n",
    "    def print_shapes(self):\n",
    "        for layer in self.layers:\n",
    "            layer.print_shapes()\n",
    "    \n",
    "    def save_model(self,path):\n",
    "        model=[self.layers,self.optimizer,self.loss]\n",
    "\n",
    "        file=open(path,\"wb\")\n",
    "        print(\"dumped model: \",model)\n",
    "\n",
    "        pickle.dump(model,file)\n",
    "\n",
    "        file.close()\n",
    "\n",
    "    def load_model(self,path):\n",
    "        file=open(path,\"rb\")\n",
    "\n",
    "        model=pickle.load(file)\n",
    "\n",
    "        file.close()\n",
    "        print(\"loaded model: \",model)\n",
    "        \n",
    "        self.layers,self.optimizer,self.loss=model\n",
    "        self.initialize_loss()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46666, 3593)\n",
      "(20000, 3593)\n",
      "(46666, 1)\n",
      "(20000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(tf_x_train.shape)\n",
    "print(tf_x_test.shape)\n",
    "Y_train.reshape(Y_train.shape[0],1)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "adam= AdamOptimizer(beta1 = 0.9,beta2 = 0.99,alpha=1,eps=0.001)\n",
    "nn = NN(loss=\"binary_cross\",optimizer=adam)\n",
    "\n",
    "nn.add_layer(tf_x_train.shape[1],64,activation=\"relu\",name=\"l1\")\n",
    "nn.add_layer(64,32,activation = \"relu\",name=\"l2\")\n",
    "# nn.add_layer(32,16,activation = \"relu\",name=\"l3\")\n",
    "nn.add_layer(32,8,activation = \"relu\",name=\"l4\")\n",
    "nn.add_layer(8,1,activation = \"sigmoid\",name=\"l5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46666, 3593)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adam.reset_params(nn.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoche 1/1\n",
      "loss= 0.04770385741062807\n",
      "Finished....\n"
     ]
    }
   ],
   "source": [
    "nn.fit(tf_x_train,Y_train,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test: (20000, 3593)\n"
     ]
    }
   ],
   "source": [
    "y_pred=nn.predict(tf_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.86296473e-11] [0.9999998]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.87932660e-01, 2.15720835e-02, 6.25458706e-02, ...,\n",
       "       4.00375760e-03, 2.80340283e-06, 6.39030687e-03])"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(min(y_pred))\n",
    "# max(y_pred)\n",
    "np.unique(y_pred)\n",
    "y2=y_pred[y_pred<0.5]\n",
    "\n",
    "print(min(y_pred),max(y_pred))\n",
    "y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99863292, 0.96466802, 0.99902475, ..., 0.99972351, 0.96872718,\n",
       "       0.99988759])"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y3= y_pred[y_pred>=0.5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.]), array([ 6538, 13462]))"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y4=y_pred.copy()\n",
    "y4[y4>=0.5]=1\n",
    "y4[y4<0.5]=0\n",
    "np.unique(y4,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dumped model:  [[<__main__.Layer object at 0x7f8c78b23640>, <__main__.Layer object at 0x7f8c78c1af40>, <__main__.Layer object at 0x7f8c78c1a400>, <__main__.Layer object at 0x7f8c8456c670>], <__main__.AdamOptimizer object at 0x7f8c78b23e20>]\n"
     ]
    }
   ],
   "source": [
    "nn.save_model(\"modelDump.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model:  [[<__main__.Layer object at 0x7f8c78c01640>, <__main__.Layer object at 0x7f8c78a3de20>, <__main__.Layer object at 0x7f8c78a3d1c0>, <__main__.Layer object at 0x7f8c78a3d580>], <__main__.AdamOptimizer object at 0x7f8c7a573730>]\n"
     ]
    }
   ],
   "source": [
    "loadedNN= NN(lr=0.01,loss=\"binary_cross\",optimizer=adam)\n",
    "loadedNN.load_model(\"modelDump.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer i=  0 \n",
      "###################\n",
      "name:  l1\n",
      "dW:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] W:  [[ 0.09329637  0.0219642   0.14563274 ... -0.08334918 -0.11055184\n",
      "  -0.17838875]\n",
      " [ 0.06012486 -0.07319563  0.13958616 ...  0.037964   -0.07443076\n",
      "  -0.02376223]\n",
      " [ 0.07058842 -0.02897183  0.16069103 ... -0.07785164 -0.09886404\n",
      "   0.10261401]\n",
      " ...\n",
      " [-0.00928848 -0.04190254  0.01456637 ...  0.03001082  0.05063087\n",
      "   0.08264691]\n",
      " [-0.14007669 -0.03305241  0.08963179 ...  0.00556524  0.00100418\n",
      "   0.04729674]\n",
      " [-0.21262609  0.08992008 -0.01326203 ... -0.0193908  -0.06945065\n",
      "  -0.0300281 ]]\n",
      "layer i=  1 \n",
      "###################\n",
      "name:  l2\n",
      "dW:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] W:  [[-0.20247318 -0.02339464  0.13343745 ... -0.04334661  0.10004348\n",
      "   0.00333405]\n",
      " [ 0.17874812 -0.12146299 -0.12571402 ...  0.1721688   0.17692784\n",
      "  -0.03043134]\n",
      " [ 0.04409772 -0.20066477 -0.09179822 ...  0.23403046 -0.30941631\n",
      "  -0.17556751]\n",
      " ...\n",
      " [-0.14634121  0.12216405  0.06999171 ... -0.27225531 -0.48223309\n",
      "   0.20533551]\n",
      " [-0.20353405  0.11385273 -0.0916302  ... -0.01718319 -0.0783313\n",
      "   0.25941146]\n",
      " [-0.17428259 -0.13003908  0.11368819 ... -0.08477363  0.07842761\n",
      "  -0.29915913]]\n",
      "layer i=  2 \n",
      "###################\n",
      "name:  l4\n",
      "dW:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0.]] W:  [[ 9.45185070e-02 -1.54749352e-01  3.43824465e-02  8.64220177e-02\n",
      "  -3.49318271e-03 -3.66402184e-01  1.45876149e-01 -2.05928663e-01\n",
      "   1.34761510e-01 -1.03044778e-01  3.20107063e-01  7.65290116e-01\n",
      "  -4.96226465e-01 -6.15159297e-01 -2.23134121e-01 -1.47652574e-01\n",
      "  -2.25618581e-01 -1.33371071e-01 -2.54176907e-01  3.21705653e-01\n",
      "  -9.75282497e-02 -2.70220005e-01 -1.18135379e-01  3.57155288e-01\n",
      "   3.58083136e-04  3.06895288e-01 -3.96051625e-01  4.12280412e-01\n",
      "  -2.34992963e-01  2.78473692e-01  2.10281275e-01  1.85784448e-01]\n",
      " [ 9.76158971e-03 -2.50007647e-01  5.63748830e-02 -8.31809881e-02\n",
      "   1.85435430e-01  4.80809699e-01 -3.13898703e-03 -2.12172593e-02\n",
      "   1.73934796e-01 -2.37452721e-02 -8.51033944e-02  1.18053240e-01\n",
      "  -1.09902723e-01 -1.46426393e-01 -1.35050199e-02 -4.08578402e-01\n",
      "  -5.71534702e-01 -3.46726352e-01 -8.98678695e-02 -3.95185094e-02\n",
      "   5.49761239e-03  2.58442516e-01 -1.64853053e-02  1.58610286e-01\n",
      "   6.91890502e-02 -1.60373292e-01 -4.13826339e-02 -6.25226484e-02\n",
      "  -2.30393657e-02 -4.48427958e-01  3.38401570e-01  1.16881210e-04]\n",
      " [ 3.63578613e-01  2.46465236e-01 -5.04183613e-01 -1.54706481e-01\n",
      "  -1.01099157e-01 -7.84848649e-02 -1.04237700e-01  3.09289289e-01\n",
      "  -2.27607368e-01  2.00945469e-01 -6.89111093e-02  8.90029083e-02\n",
      "  -2.63258860e-01 -8.23512964e-02  2.15546087e-01 -1.82149941e-01\n",
      "   3.84848041e-02 -2.52530038e-02 -2.34133890e-01 -4.07318084e-03\n",
      "  -6.20514384e-02  1.52738732e-01  7.64864874e-01  7.13359368e-03\n",
      "   2.09273584e-01 -2.18499167e-01  2.00306463e-01  2.10828905e-01\n",
      "  -1.62690065e-01  8.99207288e-02  2.16370074e-02  2.98894398e-01]\n",
      " [-5.16557667e-01  1.00591938e-03  4.54963018e-01  6.27697133e-02\n",
      "  -1.51778711e-01 -2.82744452e-02  5.49309387e-02 -2.81913653e-01\n",
      "   5.92981786e-01 -9.02134590e-02  1.57532405e-01  3.49103191e-02\n",
      "   2.76526563e-01  6.41098188e-02  4.44594113e-02  1.60098578e-01\n",
      "   2.32716496e-01 -5.29553184e-01  3.57598204e-01  3.21669411e-01\n",
      "   5.22034608e-02 -2.43432853e-01  4.74757297e-02 -1.05393808e-01\n",
      "   5.18741067e-01 -1.16327646e-01  2.32162976e-02 -2.17075666e-01\n",
      "   4.48935056e-01 -1.08900838e-01 -1.67126269e-01  4.38680226e-01]\n",
      " [-3.18968262e-01  8.64554156e-02 -2.44930437e-01 -8.09348089e-02\n",
      "  -6.35135293e-02  8.98785245e-02 -1.15679596e-01  1.92911780e-01\n",
      "   8.77836417e-03  9.05227915e-02  2.39930462e-01 -8.43492588e-02\n",
      "   6.35532661e-01 -7.22986508e-02  5.70621974e-02 -4.21236743e-01\n",
      "  -9.46473321e-02  2.68018713e-01 -1.24745464e-01  5.91624236e-02\n",
      "  -5.53066030e-01  3.32843496e-01 -1.66384704e-01 -1.04446302e-01\n",
      "  -1.22463022e-01  9.10883944e-02 -2.77461496e-01 -1.68627198e-01\n",
      "   2.07692901e-01  9.45332315e-02 -1.34372417e-02 -2.13301085e-01]\n",
      " [ 1.23924681e-01  1.34000316e-02 -1.48782166e-01  9.01003398e-02\n",
      "  -1.42804912e-01 -4.31550106e-01 -2.66550904e-01 -3.16270899e-01\n",
      "   1.18259298e-01 -6.01262343e-01 -2.68011153e-01  1.85280331e-01\n",
      "  -1.64065442e-01  6.29567813e-01 -3.14103669e-02 -5.15204976e-03\n",
      "   1.11276124e-01  3.58914289e-01 -4.90179077e-01  9.07017493e-02\n",
      "   6.42743274e-01 -2.64637655e-02  2.43494680e-01  3.65410373e-01\n",
      "   2.99653883e-01  3.22101781e-01  4.61077375e-01  7.83929947e-02\n",
      "   1.09942597e-02 -4.48795243e-02 -1.54728632e-01  2.03784351e-02]\n",
      " [-2.62650743e-01  2.66029267e-01 -2.77715069e-01  2.76458558e-03\n",
      "   1.34298631e-01 -3.11896974e-01  1.69647546e-01 -5.53782229e-01\n",
      "   6.37582687e-03 -2.50794906e-02 -2.98446630e-02 -8.84834874e-02\n",
      "  -3.61051893e-01  3.14361930e-01 -4.20844536e-02 -5.93473344e-01\n",
      "   3.84980992e-02  3.05981842e-01 -3.69198243e-01  1.65164906e-01\n",
      "   1.38808692e-01  3.84379340e-02 -1.60995522e-01  9.91357117e-02\n",
      "  -3.32345775e-01  5.41579070e-02 -2.26730785e-01  4.21133320e-02\n",
      "   3.48804056e-01 -2.02859918e-01  9.21134737e-02  2.67957696e-01]\n",
      " [ 7.37916031e-02 -1.77203086e-01  1.07629742e-01 -2.04419835e-01\n",
      "   1.22285120e-01 -2.46691956e-03  5.74477430e-02  1.95414713e-01\n",
      "  -3.26696183e-01  4.35990720e-01 -9.14223483e-03 -7.21753118e-02\n",
      "  -2.41874172e-04 -1.19122315e-01 -2.32963491e-01 -2.48513755e-01\n",
      "   8.80409122e-02 -3.06733461e-01  3.05052616e-02  2.28486572e-01\n",
      "  -5.64655523e-02 -2.29384118e-01 -2.37615270e-01  4.23327025e-02\n",
      "  -1.89970271e-01 -3.52879701e-03 -2.85486223e-01 -1.38097452e-01\n",
      "   2.61935594e-01  7.85947625e-02 -3.87424241e-01  4.03000624e-02]]\n",
      "layer i=  3 \n",
      "###################\n",
      "name:  l5\n",
      "dW:  [[0. 0. 0. 0. 0. 0. 0. 0.]] W:  [[-0.13966168 -0.33261386  0.54376299 -0.51918636  0.68976956  0.53703009\n",
      "  -0.086613    0.47068648]]\n"
     ]
    }
   ],
   "source": [
    "loadedNN.print_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['out.pckl']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "# dump=pickle.dumps(nn)\n",
    "dump(nn,\"out.pckl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.20683907]\n",
      " [0.22103681]\n",
      " [0.22143776]]\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "loadedCLF=load(\"out.pckl\")\n",
    "y_pred2=loadedCLF.predict(tf_x_test)\n",
    "y_pred2\n",
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn.metrics as metrics\n",
    "import sklearn.model_selection as ms\n",
    "import sklearn.preprocessing as preprocess\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.90      0.72      6538\n",
      "         1.0       0.94      0.71      0.81     13462\n",
      "\n",
      "    accuracy                           0.77     20000\n",
      "   macro avg       0.77      0.81      0.77     20000\n",
      "weighted avg       0.83      0.77      0.78     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Y_test\n",
    "print(classification_report(y4,Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "tf_list= pd.read_csv('/first.txt')\n",
    "array_tf_list = np.array(tf_list)\n",
    "test_list=pd.read_csv('/second.txt')\n",
    "array_test_list = np.array(test_list)\n",
    "tlabels= pd.read_csv('/third.txt')\n",
    "array_tlabels= np.array(tlabels)\n",
    "\n",
    "label_test=pd.read_csv('/fourth.txt')\n",
    "arr_lt= np.array(label_test)\n",
    "array_tf_list=np.reshape(array_tf_list,[256,5999])\n",
    "train_label_onehot =np.zeros((10,5999))\n",
    "for i in range(6000-1):\n",
    "  value=array_tlabels[i]\n",
    "  for row in range (1,10,1):\n",
    "    if (value==row):\n",
    "      train_label_onehot[value,i]=1\n",
    "\n",
    "def sigmoid(Z):\n",
    "    A = 1/(1+np.exp(-Z))\n",
    "    cache = Z\n",
    "    return A, cache\n",
    "\n",
    "def relu(Z):\n",
    "    A = np.maximum(0,Z)\n",
    "    cache = Z\n",
    "    return A, cache\n",
    "\n",
    "def softmax(Z):\n",
    "    e_x = np.exp(Z)\n",
    "    A= e_x / np.sum(np.exp(Z))\n",
    "    cache=Z\n",
    "    return A,cache\n",
    "\n",
    "def relu_backward(dA, cache):\n",
    "    Z = cache\n",
    "    dZ = np.array(dA, copy=True)\n",
    "    dZ[Z <= 0] = 0\n",
    "    assert (dZ.shape == Z.shape)\n",
    "    return dZ\n",
    "\n",
    "def sigmoid_backward(dA, cache):\n",
    "    Z = cache\n",
    "    s = 1/(1+np.exp(-Z))\n",
    "    dZ = dA * s * (1-s)\n",
    "    assert (dZ.shape == Z.shape)\n",
    "    return dZ\n",
    "\n",
    "def softmax_backward(Z,cache):\n",
    "    Z=cache\n",
    "    length=10\n",
    "    dZ=np.zeros((6000-1,10))\n",
    "    Z=np.transpose(Z)\n",
    "    for row in range (0,5999):\n",
    "            den=(np.sum(np.exp(Z[row,:])))*(np.sum(np.exp(Z[row,:])))\n",
    "            for col in range (0,10):\n",
    "                sums=0\n",
    "                for j in range (0,10):\n",
    "                    if (j!=col):\n",
    "                        sums=sums+(math.exp(Z[row,j]))\n",
    "\n",
    "                dZ[row,col]=(math.exp(Z[row,col])*sums)/den\n",
    "    dZ=np.transpose(dZ)\n",
    "    Z=np.transpose(Z)\n",
    "    assert (dZ.shape == Z.shape)\n",
    "    return dZ\n",
    "\n",
    "def initialize_parameters_deep(mylay_dimensions):\n",
    "    parameters = {}\n",
    "    L = len(mylay_dimensions)\n",
    "    for l in range(1, L):\n",
    "        parameters['W' + str(l)] = np.random.randn(mylay_dimensions[l], mylay_dimensions[l-1]) / np.sqrt(mylay_dimensions[l-1]) #*0.01\n",
    "        parameters['b' + str(l)] = np.zeros((mylay_dimensions[l], 1))\n",
    "    return parameters\n",
    "\n",
    "def for_front(A, W, b):\n",
    "    Z = np.dot(W,A) +b\n",
    "    cache = (A, W, b)\n",
    "    assert(Z.shape == (W.shape[0], A.shape[1]))\n",
    "    return Z, cache\n",
    "\n",
    "def for_active(A_prev, W, b, activation):\n",
    "    if activation == \"sigmoid\":\n",
    "        Z, linear_cache = for_front(A_prev, W, b)\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "    elif activation == \"relu\":\n",
    "        Z, linear_cache = for_front(A_prev, W, b)\n",
    "        A, activation_cache = relu(Z)\n",
    "    elif activation == \"softmax\":\n",
    "        Z, linear_cache = for_front(A_prev, W, b)\n",
    "        A, activation_cache = softmax(Z)\n",
    "    cache = (linear_cache, activation_cache)\n",
    "    return A, cache\n",
    "\n",
    "def my_mod_for(X, parameters):\n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters)\n",
    "    for l in range(1, L):\n",
    "        A_prev = A\n",
    "        A, cache = for_active(A_prev, parameters['W' + str(l)], parameters['b' + str(l)], activation = \"relu\")\n",
    "        caches.append(cache)\n",
    "    AL, cache = for_active(A, parameters['W' + str(L)], parameters['b' + str(L)], activation = \"softmax\")\n",
    "    caches.append(cache)\n",
    "    return AL, caches\n",
    "\n",
    "def calc_cost(AL, Y):\n",
    "    m = Y.shape[1]\n",
    "    cost = (-1 / m) * np.sum(np.multiply(Y, np.log(AL)) + np.multiply(1 - Y, np.log(1 - AL)))\n",
    "    return cost\n",
    "\n",
    "def linear_backward(dZ, cache):\n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "    dW = 1./m * np.dot(dZ,A_prev.T)\n",
    "    db = (1/m)*np.sum(dZ, axis=1, keepdims=True);\n",
    "    dA_prev = np.dot(W.T,dZ)\n",
    "    return dA_prev, dW, db\n",
    "\n",
    "def lin_back(dA, cache, activation):\n",
    "    linear_cache, activation_cache = cache\n",
    "    if activation == \"relu\":\n",
    "        dZ = relu_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "    elif activation == \"sigmoid\":\n",
    "        dZ = sigmoid_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "    elif activation == \"softmax\":\n",
    "        dZ = softmax_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "    return dA_prev, dW, db\n",
    "\n",
    "def my_mod_back(AL, Y, caches):\n",
    "    arbit_arr = {}\n",
    "    L = len(caches)\n",
    "    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
    "    M=len(my_network_dimensions)\n",
    "    current_cache = caches[M-2]\n",
    "    arbit_arr[\"dA\"+str(M-1)], arbit_arr[\"dW\"+str(M-1)], arbit_arr[\"db\"+str(M-1)] = lin_back(dAL, current_cache, activation = \"softmax\")#M-1\n",
    "    for l in reversed(range(L-1)):\n",
    "        current_cache = caches[l]\n",
    "        dA_prev_temp, dW_temp, db_temp = lin_back(arbit_arr[\"dA\" + str(l + 2)], current_cache, activation = \"relu\")\n",
    "        arbit_arr[\"dA\" + str(l + 1)] = dA_prev_temp\n",
    "        arbit_arr[\"dW\" + str(l + 1)] = dW_temp\n",
    "        arbit_arr[\"db\" + str(l + 1)] = db_temp\n",
    "    return arbit_arr\n",
    "\n",
    "def change_weights(parameters, arbit_arr, learning_rate):\n",
    "    for l in range(len_update-1):\n",
    "        parameters[\"W\" + str(l+1)] =parameters[\"W\" + str(l+1)] - (learning_rate*arbit_arr[\"dW\" + str(l+1)])\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - (learning_rate*arbit_arr[\"db\" + str(l+1)])\n",
    "    return parameters\n",
    "\n",
    "def plot_graph(cost_plot):\n",
    "    x_value=list(range(1,len(cost_plot)+1))\n",
    "    plt.xlabel('iteration')\n",
    "    plt.ylabel('cost')\n",
    "    plt.plot(x_value,cost_plot,0.,color='g')\n",
    "my_network_dimensions = [256,150,100,50,10]\n",
    "len_update=len(my_network_dimensions)\n",
    "def my_lay_mod(X, Y, my_network_dimensions, learning_rate , num_iterations , print_cost=False):#lr was 0.009\n",
    "    costs = []\n",
    "    cost_plot=np.zeros(num_iterations)\n",
    "    parameters = initialize_parameters_deep(my_network_dimensions)\n",
    "    for i in range(0, num_iterations):\n",
    "        AL, caches = my_mod_for(X, parameters)\n",
    "        cost =calc_cost(AL, Y)\n",
    "        arbit_arr = my_mod_back(AL, Y, caches)\n",
    "        parameters = change_weights(parameters, arbit_arr, learning_rate)\n",
    "        cost_plot[i]=cost;\n",
    "    plot_graph(cost_plot)\n",
    "    return parameters\n",
    "parameters = my_lay_mod(array_tf_list, train_label_onehot, my_network_dimensions,learning_rate = 0.005, num_iterations =50 , print_cost = True)\n",
    "for weight in parameters:\n",
    "    print(weight)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "detect_language.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
